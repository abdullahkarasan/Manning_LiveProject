{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18c7904",
   "metadata": {},
   "source": [
    "# Task-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5bd493",
   "metadata": {},
   "source": [
    "# Deep Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55aa9b",
   "metadata": {},
   "source": [
    "Deep learning models provides us a strong modeling alternatives for time series. Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) are two primary models used in time series modeling. I will start off with the RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23ac1e",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6db801",
   "metadata": {},
   "source": [
    "Let's import the libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b97bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from tensorflow.keras.metrics import AUC\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dropout, Flatten, Dense\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "#import logging\n",
    "#tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8125eb1",
   "metadata": {},
   "source": [
    "As you notice above, I tried to define optimum number of lags in time series models. In RNN and LSTM, this optimum number of lags is defined as `n_steps`, which takes the value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa45b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a636f",
   "metadata": {},
   "source": [
    "In order to separate dependent and independent variables, I applied the following code snippet. I picked the `n_steps` as 10, indicating that I have 10 lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2386ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e347fea",
   "metadata": {},
   "source": [
    "RNN, similar to LSTM, has a different input structure than the traditional time series models. As input, `sample`, `time steps`, and `number of features` need to be defined. So, we need to create 3-dimensional data as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb074358",
   "metadata": {},
   "source": [
    "**Samples:** This is the length of the data or observations.\n",
    "\n",
    "**Time steps:** This is equivalent to the amount of time steps (or `n_steps`) you run your recurrent neural network. You can think of number of lags in model and it is 10 in this model.\n",
    "\n",
    "**Features:** This is the amount of features in every time step and this is 1 in this case. As a side note: deep learning models allow us to process multivariate structure, which is not possible in traditional time series modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319a251",
   "metadata": {},
   "source": [
    "Scaling matters in deep learning and here `MinMaxScaler()` is used and to convert 1-dimensional data into 3-dimensional one, `np.reshape()` is applied. This is applied both for training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888f06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices = pd.read_csv('stock_prices.csv')\n",
    "arima_predictions_T = pd.read_csv('arima_predictions_T')\n",
    "arima_predictions_VZ = pd.read_csv('arima_predictions_VZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0839a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_VZ = stock_prices['VZ'].diff().dropna()\n",
    "diff_T = stock_prices['T'].diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7884431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(diff_VZ.values)*0.95)\n",
    "diff_train_T = diff_T.iloc[:split]\n",
    "diff_test_T = diff_T.iloc[split:]\n",
    "diff_train_VZ = diff_VZ.iloc[:split]\n",
    "diff_test_VZ = diff_VZ.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d4b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diff_train_T, y_diff_train_T = split_sequence(diff_train_T, n_steps)\n",
    "X_diff_train_T = X_diff_train_T.reshape((X_diff_train_T.shape[0],\n",
    "                                         X_diff_train_T.shape[1], n_features))\n",
    "\n",
    "X_diff_test_T, y_diff_test_T = split_sequence(diff_test_T.values, n_steps)\n",
    "X_diff_test_T = X_diff_test_T.reshape((X_diff_test_T.shape[0],\n",
    "                                       X_diff_test_T.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5a990",
   "metadata": {},
   "source": [
    "In the following code block, using python customize functionm I create an RNN structure with one hidden layer with 128 neurons. In addition, `dropout` is included to deal with overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60d18e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_part():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128,\n",
    "              input_shape=(n_steps, n_features),\n",
    "              return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam' , loss='mean_squared_error', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f5adb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 191ms/step - loss: 0.4383 - mse: 0.4383 - val_loss: 0.1378 - val_mse: 0.1378\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3670 - mse: 0.3670 - val_loss: 0.1230 - val_mse: 0.1230\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.3161 - mse: 0.3161 - val_loss: 0.1001 - val_mse: 0.1001\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2969 - mse: 0.2969 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2644 - mse: 0.2644 - val_loss: 0.0829 - val_mse: 0.0829\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2344 - mse: 0.2344 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2171 - mse: 0.2171 - val_loss: 0.0686 - val_mse: 0.0686\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1907 - mse: 0.1907 - val_loss: 0.0580 - val_mse: 0.0580\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1852 - mse: 0.1852 - val_loss: 0.0508 - val_mse: 0.0508\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1686 - mse: 0.1686 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1372 - mse: 0.1372 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1163 - mse: 0.1163 - val_loss: 0.0374 - val_mse: 0.0374\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1063 - mse: 0.1063 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0937 - mse: 0.0937 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0665 - mse: 0.0665 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0579 - mse: 0.0579 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0401 - mse: 0.0401 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0297 - mse: 0.0297 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 8.1138e-04 - val_mse: 8.1138e-04\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 7.0363e-04 - val_mse: 7.0363e-04\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 6.7104e-04 - val_mse: 6.7104e-04\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 5.9949e-04 - val_mse: 5.9949e-04\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 4.4388e-04 - val_mse: 4.4388e-04\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 3.7228e-04 - val_mse: 3.7228e-04\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 2.9573e-04 - val_mse: 2.9573e-04\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 2.5791e-04 - val_mse: 2.5791e-04\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 2.1997e-04 - val_mse: 2.1997e-04\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 3.3940e-04 - val_mse: 3.3940e-04\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 2.4161e-04 - val_mse: 2.4161e-04\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 3.0218e-04 - val_mse: 3.0218e-04\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 6.7975e-04 - val_mse: 6.7975e-04\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 5.7405e-04 - val_mse: 5.7405e-04\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 2.3837e-04 - val_mse: 2.3837e-04\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 4.6238e-04 - val_mse: 4.6238e-04\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 4.5589e-04 - val_mse: 4.5589e-04\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 2.7081e-04 - val_mse: 2.7081e-04\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.1454e-04 - val_mse: 2.1454e-04\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 2.0848e-04 - val_mse: 2.0848e-04\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 3.8744e-04 - val_mse: 3.8744e-04\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 2.0755e-04 - val_mse: 2.0755e-04\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.9551e-04 - val_mse: 1.9551e-04\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 2.3759e-04 - val_mse: 2.3759e-04\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 2.2591e-04 - val_mse: 2.2591e-04\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.0560e-04 - val_mse: 2.0560e-04\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 1.3141e-04 - val_mse: 1.3141e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 1.3224e-04 - val_mse: 1.3224e-04\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.3467e-04 - val_mse: 1.3467e-04\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.2622e-04 - val_mse: 1.2622e-04\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.2370e-04 - val_mse: 2.2370e-04\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.3649e-04 - val_mse: 2.3649e-04\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.0015e-04 - val_mse: 2.0015e-04\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.3434e-04 - val_mse: 1.3434e-04\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 1.7182e-04 - val_mse: 1.7182e-04\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.6333e-04 - val_mse: 2.6333e-04\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 1.9135e-04 - val_mse: 1.9135e-04\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 4.3253e-04 - val_mse: 4.3253e-04\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 3.8728e-04 - val_mse: 3.8728e-04\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 9.9889e-05 - val_mse: 9.9889e-05\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.6720e-04 - val_mse: 2.6720e-04\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 3.5710e-04 - val_mse: 3.5710e-04\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 1.5232e-04 - val_mse: 1.5232e-04\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.5188e-04 - val_mse: 1.5188e-04\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 3.1911e-04 - val_mse: 3.1911e-04\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 2.4996e-04 - val_mse: 2.4996e-04\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.1325e-04 - val_mse: 1.1325e-04\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.2429e-04 - val_mse: 2.2429e-04\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.6614e-04 - val_mse: 2.6614e-04\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.3978e-04 - val_mse: 1.3978e-04\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.5246e-04 - val_mse: 1.5246e-04\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.0522e-04 - val_mse: 2.0522e-04\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.3446e-04 - val_mse: 1.3446e-04\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.9432e-04 - val_mse: 1.9432e-04\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.3488e-04 - val_mse: 1.3488e-04\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.1436e-04 - val_mse: 1.1436e-04\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.0341e-04 - val_mse: 2.0341e-04\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.4252e-04 - val_mse: 1.4252e-04\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 8.3959e-05 - val_mse: 8.3959e-05\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 1.4011e-04 - val_mse: 1.4011e-04\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 9.8184e-05 - val_mse: 9.8184e-05\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.3024e-04 - val_mse: 1.3024e-04\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.8191e-04 - val_mse: 1.8191e-04\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.7060e-04 - val_mse: 1.7060e-04\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.7035e-04 - val_mse: 1.7035e-04\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.9266e-04 - val_mse: 1.9266e-04\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.1506e-04 - val_mse: 1.1506e-04\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.5950e-04 - val_mse: 1.5950e-04\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.9593e-04 - val_mse: 2.9593e-04\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.3081e-04 - val_mse: 1.3081e-04\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.3166e-04 - val_mse: 1.3166e-04\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.2838e-04 - val_mse: 1.2838e-04\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 6.3628e-05 - val_mse: 6.3628e-05\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 8.0610e-05 - val_mse: 8.0610e-05\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.0215e-04 - val_mse: 1.0215e-04\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.2849e-04 - val_mse: 1.2849e-04\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 5.5421e-05 - val_mse: 5.5421e-05\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 5.7614e-05 - val_mse: 5.7614e-05\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 7.7108e-05 - val_mse: 7.7108e-05\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 5.5633e-05 - val_mse: 5.5633e-05\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 8.0641e-05 - val_mse: 8.0641e-05\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 5.8487e-05 - val_mse: 5.8487e-05\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 6.4612e-05 - val_mse: 6.4612e-05\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 7.8688e-05 - val_mse: 7.8688e-05\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 8.7496e-05 - val_mse: 8.7496e-05\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 7.2723e-05 - val_mse: 7.2723e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 8.7653e-05 - val_mse: 8.7653e-05\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 7.7233e-05 - val_mse: 7.7233e-05\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 5.8069e-05 - val_mse: 5.8069e-05\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 5.5640e-05 - val_mse: 5.5640e-05\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 9.0953e-05 - val_mse: 9.0953e-05\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.1159e-04 - val_mse: 1.1159e-04\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 8.9995e-05 - val_mse: 8.9995e-05\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 9.3242e-05 - val_mse: 9.3242e-05\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.7453e-04 - val_mse: 1.7453e-04\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.9134e-04 - val_mse: 1.9134e-04\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.5321e-04 - val_mse: 1.5321e-04\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.1901e-04 - val_mse: 2.1901e-04\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.6097e-04 - val_mse: 1.6097e-04\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.1203e-04 - val_mse: 1.1203e-04\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.2054e-04 - val_mse: 1.2054e-04\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.2394e-04 - val_mse: 2.2394e-04\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.0197e-04 - val_mse: 1.0197e-04\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.6814e-04 - val_mse: 1.6814e-04\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.3060e-04 - val_mse: 2.3060e-04\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.2518e-04 - val_mse: 1.2518e-04\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.0993e-04 - val_mse: 2.0993e-04\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 2.5673e-04 - val_mse: 2.5673e-04\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 8.7775e-05 - val_mse: 8.7775e-05\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.1605e-04 - val_mse: 2.1605e-04\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.3187e-04 - val_mse: 2.3187e-04\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 9.1345e-05 - val_mse: 9.1345e-05\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.6721e-04 - val_mse: 2.6721e-04\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.3196e-04 - val_mse: 2.3196e-04\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.0422e-04 - val_mse: 1.0422e-04\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.3306e-04 - val_mse: 1.3306e-04\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.6338e-04 - val_mse: 1.6338e-04\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.7624e-04 - val_mse: 1.7624e-04\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.6455e-04 - val_mse: 1.6455e-04\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.0193e-04 - val_mse: 1.0193e-04\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 6.6659e-05 - val_mse: 6.6659e-05\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.7325e-04 - val_mse: 1.7325e-04\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.5692e-04 - val_mse: 1.5692e-04\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 7.2497e-05 - val_mse: 7.2497e-05\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 8.2830e-05 - val_mse: 8.2830e-05\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.0308e-04 - val_mse: 1.0308e-04\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 5.5317e-05 - val_mse: 5.5317e-05\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 6.6589e-05 - val_mse: 6.6589e-05\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 6.3312e-05 - val_mse: 6.3312e-05\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 6.8705e-05 - val_mse: 6.8705e-05\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 8.9912e-05 - val_mse: 8.9912e-05\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.0072e-04 - val_mse: 1.0072e-04\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 8.4120e-05 - val_mse: 8.4120e-05\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 8.0615e-05 - val_mse: 8.0615e-05\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 5.5521e-05 - val_mse: 5.5521e-05\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 5.9451e-05 - val_mse: 5.9451e-05\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 7.2426e-05 - val_mse: 7.2426e-05\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.1291e-04 - val_mse: 1.1291e-04\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.0345e-04 - val_mse: 1.0345e-04\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.0313e-04 - val_mse: 1.0313e-04\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 8.6740e-05 - val_mse: 8.6740e-05\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.0362e-04 - val_mse: 1.0362e-04\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5335e-04 - val_mse: 1.5335e-04\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.2828e-04 - val_mse: 1.2828e-04\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.4689e-04 - val_mse: 1.4689e-04\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.4302e-04 - val_mse: 1.4302e-04\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 8.9309e-05 - val_mse: 8.9309e-05\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.2763e-04 - val_mse: 1.2763e-04\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 2.2527e-04 - val_mse: 2.2527e-04\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.1676e-04 - val_mse: 1.1676e-04\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 9.4778e-05 - val_mse: 9.4778e-05\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.1447e-04 - val_mse: 1.1447e-04\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.0638e-04 - val_mse: 1.0638e-04\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 8.0575e-05 - val_mse: 8.0575e-05\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.1305e-04 - val_mse: 1.1305e-04\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.2735e-04 - val_mse: 1.2735e-04\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.1393e-04 - val_mse: 1.1393e-04\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.8260e-04 - val_mse: 1.8260e-04\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.5538e-04 - val_mse: 1.5538e-04\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 9.2086e-05 - val_mse: 9.2086e-05\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.0312e-04 - val_mse: 1.0312e-04\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.8252e-04 - val_mse: 1.8252e-04\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.7191e-04 - val_mse: 1.7191e-04\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.4477e-04 - val_mse: 1.4477e-04\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 9.4003e-05 - val_mse: 9.4003e-05\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.3831e-04 - val_mse: 1.3831e-04\n"
     ]
    }
   ],
   "source": [
    "RNN_model = RNN_part()\n",
    "history_RNN = RNN_model.fit(X_diff_train_T, y_diff_train_T,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09d2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = X_diff_test_T[X_diff_test_T.shape[0]-1]\n",
    "T_input = start\n",
    "T_input = T_input.reshape((1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0f5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_T = []\n",
    "\n",
    "for i in range(len(arima_predictions_T)):\n",
    "    T_input = T_input.reshape((1, n_steps, n_features))\n",
    "    yhat = RNN_model.predict(T_input, verbose=0)\n",
    "    T_input = np.append(T_input, yhat)\n",
    "    T_input = T_input[1:]\n",
    "    predictions_T.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c525ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,yhat):\n",
    "    return np.sqrt(mean_squared_error(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c315e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of AT&T for RNN model 0.4644\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of AT&T for RNN model {:.4f}'\\\n",
    "      .format(rmse(diff_test_T, np.array(predictions_T).flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7569fd",
   "metadata": {},
   "source": [
    "Well, the RMSE score of 0.3254, implying it outperforms the traditional time series models. We know that deep learning model works well with non-linear data. However, please also note that, it is not always the case that deep learning models is superior than the other time series model in terms of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669fef30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])\n"
     ]
    }
   ],
   "source": [
    "print(history_RNN.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece45cd6",
   "metadata": {},
   "source": [
    "Let me plot the result of loss and test loss result. It turns out, after huge spike, test loss gets back on track and confirms that RNN performs well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd6a8256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_RNN.history['loss'])\n",
    "plt.plot(history_RNN.history['val_loss'])\n",
    "plt.title('RNN model Loss')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a7cf0",
   "metadata": {},
   "source": [
    "Let me run `callback` function to see the effect of early stopping in deep learning. \n",
    "Early stopping is a tool to employ against overfitting in the sense that it helps us to regularize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9e213",
   "metadata": {},
   "source": [
    "The other pros of early stopping is to save time, because training a deep learning model takes time. In early stopping, once the model reaches the target performance, the algorithm automatically stops. In other word, thanks to `patience` paramater below, training stops after the number of epochs without improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa56b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b5fb3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.4126 - mse: 0.4126 - val_loss: 0.1385 - val_mse: 0.1385\n"
     ]
    }
   ],
   "source": [
    "RNN_model = RNN_part()\n",
    "history_RNN = RNN_model.fit(X_diff_train_T, y_diff_train_T,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2, \n",
    "                            callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68cc1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_T = []\n",
    "\n",
    "\n",
    "for i in range(len(arima_predictions_T)):\n",
    "    T_input = T_input.reshape((1, n_steps, n_features))\n",
    "    yhat = RNN_model.predict(T_input, verbose=0)\n",
    "    T_input = np.append(T_input, yhat)\n",
    "    T_input = T_input[1:]\n",
    "    predictions_T.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c81b040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of AT&T for RNN model 0.4539\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of AT&T for RNN model {:.4f}'\\\n",
    "      .format(rmse(diff_test_T, np.array(predictions_T).flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbbf50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diff_train_VZ, y_diff_train_VZ = split_sequence(diff_train_VZ, n_steps)\n",
    "X_diff_train_VZ = X_diff_train_VZ.reshape((X_diff_train_VZ.shape[0],\n",
    "                                         X_diff_train_VZ.shape[1], n_features))\n",
    "\n",
    "\n",
    "X_diff_test_VZ, y_diff_test_VZ = split_sequence(diff_test_VZ.values, n_steps)\n",
    "X_diff_test_VZ = X_diff_test_VZ.reshape((X_diff_test_VZ.shape[0],\n",
    "                                       X_diff_test_VZ.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e65c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_part():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(64,\n",
    "              input_shape=(n_steps, n_features),\n",
    "              return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam' , loss='mean_squared_error', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "750301c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.6127 - mse: 0.6127 - val_loss: 0.2130 - val_mse: 0.2130\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5945 - mse: 0.5945 - val_loss: 0.2096 - val_mse: 0.2096\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5293 - mse: 0.5293 - val_loss: 0.1921 - val_mse: 0.1921\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4959 - mse: 0.4959 - val_loss: 0.1774 - val_mse: 0.1774\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.4559 - mse: 0.4559 - val_loss: 0.1684 - val_mse: 0.1684\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4196 - mse: 0.4196 - val_loss: 0.1601 - val_mse: 0.1601\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.4072 - mse: 0.4072 - val_loss: 0.1536 - val_mse: 0.1536\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3902 - mse: 0.3902 - val_loss: 0.1465 - val_mse: 0.1465\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3557 - mse: 0.3557 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3283 - mse: 0.3283 - val_loss: 0.1326 - val_mse: 0.1326\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.3289 - mse: 0.3289 - val_loss: 0.1267 - val_mse: 0.1267\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3079 - mse: 0.3079 - val_loss: 0.1224 - val_mse: 0.1224\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2927 - mse: 0.2927 - val_loss: 0.1161 - val_mse: 0.1161\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2822 - mse: 0.2822 - val_loss: 0.1083 - val_mse: 0.1083\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.1005 - val_mse: 0.1005\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 0.0944 - val_mse: 0.0944\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2235 - mse: 0.2235 - val_loss: 0.0884 - val_mse: 0.0884\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2024 - mse: 0.2024 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1957 - mse: 0.1957 - val_loss: 0.0771 - val_mse: 0.0771\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1907 - mse: 0.1907 - val_loss: 0.0720 - val_mse: 0.0720\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1687 - mse: 0.1687 - val_loss: 0.0664 - val_mse: 0.0664\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1621 - mse: 0.1621 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1482 - mse: 0.1482 - val_loss: 0.0504 - val_mse: 0.0504\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1366 - mse: 0.1366 - val_loss: 0.0465 - val_mse: 0.0465\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1234 - mse: 0.1234 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.0407 - val_mse: 0.0407\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1168 - mse: 0.1168 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0938 - mse: 0.0938 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0750 - mse: 0.0750 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0891 - mse: 0.0891 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0718 - mse: 0.0718 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0695 - mse: 0.0695 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0621 - mse: 0.0621 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0546 - mse: 0.0546 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0482 - mse: 0.0482 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0389 - mse: 0.0389 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 6.0524e-04 - val_mse: 6.0524e-04\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 5.3932e-04 - val_mse: 5.3932e-04\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 4.2563e-04 - val_mse: 4.2563e-04\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 4.1002e-04 - val_mse: 4.1002e-04\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 7.1141e-04 - val_mse: 7.1141e-04\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 7.2262e-04 - val_mse: 7.2262e-04\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 4.6473e-04 - val_mse: 4.6473e-04\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 6.3481e-04 - val_mse: 6.3481e-04\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 5.4318e-04 - val_mse: 5.4318e-04\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 3.5290e-04 - val_mse: 3.5290e-04\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 4.4704e-04 - val_mse: 4.4704e-04\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 9.4693e-04 - val_mse: 9.4693e-04\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 9.9021e-04 - val_mse: 9.9021e-04\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 5.1730e-04 - val_mse: 5.1730e-04\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 2.3200e-04 - val_mse: 2.3200e-04\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 3.8855e-04 - val_mse: 3.8855e-04\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 7.0513e-04 - val_mse: 7.0513e-04\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 8.1256e-04 - val_mse: 8.1256e-04\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 7.6907e-04 - val_mse: 7.6907e-04\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 9.5289e-04 - val_mse: 9.5289e-04\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 9.8603e-04 - val_mse: 9.8603e-04\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 7.8397e-04 - val_mse: 7.8397e-04\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 6.6902e-04 - val_mse: 6.6902e-04\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 6.5348e-04 - val_mse: 6.5348e-04\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 7.6673e-04 - val_mse: 7.6673e-04\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 7.1167e-04 - val_mse: 7.1167e-04\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 5.4087e-04 - val_mse: 5.4087e-04\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 6.6715e-04 - val_mse: 6.6715e-04\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 7.8785e-04 - val_mse: 7.8785e-04\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 6.4783e-04 - val_mse: 6.4783e-04\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 5.6189e-04 - val_mse: 5.6189e-04\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 4.9351e-04 - val_mse: 4.9351e-04\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 4.5463e-04 - val_mse: 4.5463e-04\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 5.7232e-04 - val_mse: 5.7232e-04\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 5.3881e-04 - val_mse: 5.3881e-04\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 7.1395e-04 - val_mse: 7.1395e-04\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 6.3031e-04 - val_mse: 6.3031e-04\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 4.2062e-04 - val_mse: 4.2062e-04\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 4.6262e-04 - val_mse: 4.6262e-04\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 4.7942e-04 - val_mse: 4.7942e-04\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 3.5317e-04 - val_mse: 3.5317e-04\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 3.9138e-04 - val_mse: 3.9138e-04\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 6.4826e-04 - val_mse: 6.4826e-04\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 8.2682e-04 - val_mse: 8.2682e-04\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 5.4493e-04 - val_mse: 5.4493e-04\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 3.2525e-04 - val_mse: 3.2525e-04\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 2.2659e-04 - val_mse: 2.2659e-04\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 3.9838e-04 - val_mse: 3.9838e-04\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 5.8785e-04 - val_mse: 5.8785e-04\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 6.5072e-04 - val_mse: 6.5072e-04\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 6.3221e-04 - val_mse: 6.3221e-04\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 4.1490e-04 - val_mse: 4.1490e-04\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 3.7651e-04 - val_mse: 3.7651e-04\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 3.9256e-04 - val_mse: 3.9256e-04\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 3.2622e-04 - val_mse: 3.2622e-04\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 4.8156e-04 - val_mse: 4.8156e-04\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 8.4740e-04 - val_mse: 8.4740e-04\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 8.5235e-04 - val_mse: 8.5235e-04\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 4.5432e-04 - val_mse: 4.5432e-04\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 4.5825e-04 - val_mse: 4.5825e-04\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 6.4040e-04 - val_mse: 6.4040e-04\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 5.9357e-04 - val_mse: 5.9357e-04\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 4.5945e-04 - val_mse: 4.5945e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 5.2341e-04 - val_mse: 5.2341e-04\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 5.2068e-04 - val_mse: 5.2068e-04\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 4.7619e-04 - val_mse: 4.7619e-04\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 4.6424e-04 - val_mse: 4.6424e-04\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 4.7824e-04 - val_mse: 4.7824e-04\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 4.3349e-04 - val_mse: 4.3349e-04\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 4.0094e-04 - val_mse: 4.0094e-04\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 3.5103e-04 - val_mse: 3.5103e-04\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 3.1798e-04 - val_mse: 3.1798e-04\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 3.3417e-04 - val_mse: 3.3417e-04\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 3.8417e-04 - val_mse: 3.8417e-04\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 2.8271e-04 - val_mse: 2.8271e-04\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 3.0037e-04 - val_mse: 3.0037e-04\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 4.3370e-04 - val_mse: 4.3370e-04\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 5.0964e-04 - val_mse: 5.0964e-04\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 3.7678e-04 - val_mse: 3.7678e-04\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 2.7508e-04 - val_mse: 2.7508e-04\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 2.7752e-04 - val_mse: 2.7752e-04\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 4.5805e-04 - val_mse: 4.5805e-04\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 6.9281e-04 - val_mse: 6.9281e-04\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 5.9264e-04 - val_mse: 5.9264e-04\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 4.1398e-04 - val_mse: 4.1398e-04\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 3.3460e-04 - val_mse: 3.3460e-04\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 3.5264e-04 - val_mse: 3.5264e-04\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 3.8481e-04 - val_mse: 3.8481e-04\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 3.3070e-04 - val_mse: 3.3070e-04\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 3.0178e-04 - val_mse: 3.0178e-04\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 4.3427e-04 - val_mse: 4.3427e-04\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 5.1842e-04 - val_mse: 5.1842e-04\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 4.7006e-04 - val_mse: 4.7006e-04\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 5.3914e-04 - val_mse: 5.3914e-04\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 6.2728e-04 - val_mse: 6.2728e-04\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 6.5367e-04 - val_mse: 6.5367e-04\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 7.0060e-04 - val_mse: 7.0060e-04\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 9.3932e-04 - val_mse: 9.3932e-04\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 9.7456e-04 - val_mse: 9.7456e-04\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 5.6937e-04 - val_mse: 5.6937e-04\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 3.7237e-04 - val_mse: 3.7237e-04\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 4.6488e-04 - val_mse: 4.6488e-04\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 5.3692e-04 - val_mse: 5.3692e-04\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 4.7061e-04 - val_mse: 4.7061e-04\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 5.3136e-04 - val_mse: 5.3136e-04\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 5.7618e-04 - val_mse: 5.7618e-04\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 5.5885e-04 - val_mse: 5.5885e-04\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 4.5685e-04 - val_mse: 4.5685e-04\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 2.9302e-04 - val_mse: 2.9302e-04\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 3.8554e-04 - val_mse: 3.8554e-04\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 5.1004e-04 - val_mse: 5.1004e-04\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 4.9373e-04 - val_mse: 4.9373e-04\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 3.3707e-04 - val_mse: 3.3707e-04\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 2.7439e-04 - val_mse: 2.7439e-04\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 4.5205e-04 - val_mse: 4.5205e-04\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 4.8749e-04 - val_mse: 4.8749e-04\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 3.2192e-04 - val_mse: 3.2192e-04\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 3.1026e-04 - val_mse: 3.1026e-04\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 3.5413e-04 - val_mse: 3.5413e-04\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 4.1390e-04 - val_mse: 4.1390e-04\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 3.3269e-04 - val_mse: 3.3269e-04\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 2.9452e-04 - val_mse: 2.9452e-04\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 3.2911e-04 - val_mse: 3.2911e-04\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 3.3482e-04 - val_mse: 3.3482e-04\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 2.8163e-04 - val_mse: 2.8163e-04\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 1.6511e-04 - val_mse: 1.6511e-04\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 2.0455e-04 - val_mse: 2.0455e-04\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 2.0439e-04 - val_mse: 2.0439e-04\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 2.0475e-04 - val_mse: 2.0475e-04\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 3.0567e-04 - val_mse: 3.0567e-04\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 5.8153e-04 - val_mse: 5.8153e-04\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 6.6635e-04 - val_mse: 6.6635e-04\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 5.8186e-04 - val_mse: 5.8186e-04\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 5.0027e-04 - val_mse: 5.0027e-04\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 3.2954e-04 - val_mse: 3.2954e-04\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 2.0475e-04 - val_mse: 2.0475e-04\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 2.1753e-04 - val_mse: 2.1753e-04\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 2.6141e-04 - val_mse: 2.6141e-04\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 2.5062e-04 - val_mse: 2.5062e-04\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 2.2728e-04 - val_mse: 2.2728e-04\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 2.0935e-04 - val_mse: 2.0935e-04\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 1.8619e-04 - val_mse: 1.8619e-04\n"
     ]
    }
   ],
   "source": [
    "RNN_model = RNN_part()\n",
    "history_RNN_VZ = RNN_model.fit(X_diff_train_VZ, y_diff_train_VZ,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6f4e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = X_diff_test_VZ[X_diff_test_VZ.shape[0]-1]\n",
    "VZ_input = start\n",
    "VZ_input = VZ_input.reshape((1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68dd1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_RNN_VZ = []\n",
    "\n",
    "\n",
    "for i in range(len(arima_predictions_VZ)):\n",
    "    VZ_input = VZ_input.reshape((1, n_steps, n_features))\n",
    "    yhat = RNN_model.predict(VZ_input, verbose=0)\n",
    "    VZ_input = np.append(VZ_input, yhat)\n",
    "    VZ_input = VZ_input[1:]\n",
    "    predictions_RNN_VZ.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b187d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of VZ for RNN model 0.9001\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of VZ for RNN model {:.4f}'\\\n",
    "      .format(rmse(diff_test_VZ, np.array(predictions_RNN_VZ).flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c248b",
   "metadata": {},
   "source": [
    "Well, the RMSE score of 0.3254, implying it outperforms the traditional time series models. We know that deep learning model works well with non-linear data. However, please also note that, it is not always the case that deep learning models is superior than the other time series model in terms of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be11d",
   "metadata": {},
   "source": [
    "Let me plot the result of loss and test loss result. It turns out, after huge spike, test loss gets back on track and confirms that RNN performs well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5e52d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3P0lEQVR4nO3deXxU9bn48c8zk30PSUgCARJ22TdxQau4gitq635b7WLtrdrl117tba/1XttbtbtXW6Qtta1Va7Uqrah1Q7AisghI2HcCCWTfyDp5fn+cExxiEgOZkwnM83695pUz55z5nmfOTM4z5/s95/sVVcUYY0zk8oU7AGOMMeFlicAYYyKcJQJjjIlwlgiMMSbCWSIwxpgIZ4nAGGMinCUCYzwmIktE5Is9XFdFZKTXMRkTzBKB6VdEZLeINIhInYiUiMjjIpIUtPxx92A5M2jeSBHRoOdLRKRRRIYEzbtARHb32RvxwLEkFGOOhSUC0x9drqpJwBRgKvCdDssrgB98Qhn1wH+FPjRjTj6WCEy/paolwKs4CSHYH4BJInJONy9/GLihp9Us7lnGv4vINhGpFZH7RWSEiCwXkRoReUZEYoLW/5KIbBeRChFZJCKDgpZdKCKbRaRaRB4BpMO2Pi8im0SkUkReFZFhPYmxm9h9IvI9EdkjIodE5I8ikuouixORJ0SkXESqRGSliGS7y24RkZ3u+90lIjf1Jg5z4rJEYPotEckD5gLbOyw6DPwv8MNuXr4f+A1w3zFscg4wHTgd+A9gAXATMASYANzgxnUe8CPgWiAX2AM87S7LBJ4DvgdkAjuAWUHvaR7wn8DVQBawDHjqGGLszC3uYzYwHEgCHnGXfQ5Idd9DBnA70CAiiTjJcq6qJgNnAmt7GYc5QVkiMP3RCyJSC+wDDgHf72Sdx4ChIjK3m3J+BFwuIuN7uN0HVbVGVQuBDcA/VXWnqlYDL+NUU4GTHBaq6hpVbcKpujpDRPKBS4CNqvqsqrYAvwBKgrbxZeBHqrpJVVtxEtqUXp4V3AT8zI21zo3nehGJAlpwEsBIVQ2o6mpVrXFf1wZMEJF4VS1237eJQJYITH80z/2Vei4wFueX9VHcA/D97kM6LnfXKcX5Zfw/PdzuwaDphk6etzdaD8I5C2jfTh1QDgx2l+0LWqbBz4FhwC/dapoqnPYOcV97vI6Kx52OArKBP+FUrz0tIgdE5CERiVbVeuA6nDOEYhF5SUTG9iIGcwKzRGD6LVV9G3gc+EkXq/wep9rjqm6K+TFOlcn0EIZ2AOeADoBbzZKBUx1VjFMN075Mgp/jJIUvq2pa0CNeVd8NVTzAUKAVOKiqLar636o6Dqf65zLgswCq+qqqXohTvbUZpyrNRCBLBKa/+wVwoYhM6bjArVq5D7i7qxerahXwU5w6/1B5ErhVRKaISCxO9c4KVd0NvASMF5Gr3aqZu4CcoNfOB77TXl0lIqki8plj2HaU2wDc/ojGaWP4hogUuJfa/i/wF1VtFZHZIjJRRPxADU5VUUBEskXkCjeJNQF1QKAX+8ScwCwRmH7Nrd75I11fCvoUzq/w7vySEB7kVPUNN57n3G2PAK53l5UBnwEewKkuGgX8K+i1zwMP4lTV1OC0RXTXztHRr3GqqdofvwcW4lQBLQV2AY3Ane76OcCzOElgE/A28ATO//7/wzmbqADOAf79GOIwJxGxgWmMMSay2RmBMcZEOEsExhgT4SwRGGNMhLNEYIwxES4q3AEcq8zMTM3Pzw93GMYYc0JZvXp1mapmdbbshEsE+fn5rFq1KtxhGGPMCUVE9nS1zKqGjDEmwlkiMMaYCGeJwBhjItwJ10ZgjDHHo6WlhaKiIhobG8Mdiqfi4uLIy8sjOjq6x6+xRGCMiQhFRUUkJyeTn5+P0ynsyUdVKS8vp6ioiIKCgh6/zqqGjDERobGxkYyMjJM2CQCICBkZGcd81mOJwBgTMU7mJNDueN5jxCSCrQdr+cE/NtLYYl2uG2NMsIhJBEWVh/ntO7tYvacy3KEYYyJQVVUVv/rVr475dZdccglVVVWhDyiIp4lAROaIyBYR2S4i93SxzrkislZECkXkba9imVmQgd8nvLujzKtNGGNMl7pKBIFA97UUixcvJi0tzaOoHJ4lAndovEdxRl8aB9wgIuM6rJMG/Aq4QlXH44zs5Imk2Cgm56Xyr+3lXm3CGGO6dM8997Bjxw6mTJnCqaeeyuzZs7nxxhuZOHEiAPPmzWP69OmMHz+eBQsWHHldfn4+ZWVl7N69m1NOOYUvfelLjB8/nosuuoiGhoaQxObl5aMzge2quhNARJ4GrgQ2Bq1zI/A3Vd0LoKqHPIyHWSMzefSt7dQ0tpAS1/NrbI0xJ5f//nshGw/UhLTMcYNS+P7l47tc/sADD7BhwwbWrl3LkiVLuPTSS9mwYcORyzwXLlzIgAEDaGho4NRTT+Waa64hIyPjqDK2bdvGU089xW9+8xuuvfZannvuOW6++eZex+5l1dBgYF/Q8yJ3XrDRQLqILBGR1SLy2c4KEpHbRGSViKwqLS097oDOGJFBm8LKXRXHXYYxxoTCzJkzj7rW/+GHH2by5Mmcfvrp7Nu3j23btn3sNQUFBUyZMgWA6dOns3v37pDE4uUZQWfXMHUcIDkKmA6cD8QDy0XkPVXdetSLVBcACwBmzJhx3IMsTxuaTmyUj39tL+f8U7KPtxhjzAmuu1/ufSUxMfHI9JIlS3j99ddZvnw5CQkJnHvuuZ3eCxAbG3tk2u/3nxBVQ0XAkKDnecCBTtYpU9V6oF5ElgKTga14IC7az9jcFLYdqvWieGOM6VJycjK1tZ0fe6qrq0lPTychIYHNmzfz3nvv9WlsXiaClcAoESkA9gPX47QJBHsReEREooAY4DTg5x7GxICEaMrqmr3chDHGfExGRgazZs1iwoQJxMfHk539Ua3EnDlzmD9/PpMmTWLMmDGcfvrpfRqbZ4lAVVtF5A7gVcAPLFTVQhG53V0+X1U3icgrwHqgDfitqm7wKiaAtIQYth2q83ITxhjTqSeffLLT+bGxsbz88sudLmtvB8jMzGTDho8Oj9/61rdCFpennc6p6mJgcYd58zs8/zHwYy/jCJaWEE3V4Za+2pwxxvR7EXNncbu0+BjqmlppCbSFOxRjjOkXIi4RpCc69w/YWYExxjgiLhGkJcQAUN1gDcbGGAORmAjinTOCSjsjMMYYIAITQbp7RlBZb2cExhgDEThUZVqC20bQYGcExpi+U15ezvnnnw9ASUkJfr+frKwsAN5//31iYmK6ff2SJUuIiYnhzDPPDHlskZsIDtsZgTGm72RkZLB27VoA7rvvPpKSko7pXoAlS5aQlJTkSSKIuKqhpNgoonxiVw0ZY8Ju9erVnHPOOUyfPp2LL76Y4uJiwOmAbty4cUyaNInrr7+e3bt3M3/+fH7+858zZcoUli1bFtI4Iu6MQERIS4i2xmJjItnL90DJh6EtM2cizH2gx6urKnfeeScvvvgiWVlZ/OUvf+G73/0uCxcu5IEHHmDXrl3ExsZSVVVFWloat99++zGfRfRUxCUCcC4htaohY0w4NTU1sWHDBi688ELAGaksNzcXgEmTJnHTTTcxb9485s2b53ksEZkI0q2bCWMi2zH8cveKqjJ+/HiWL1/+sWUvvfQSS5cuZdGiRdx///0UFhZ6GkvEtREApMbHUGlnBMaYMIqNjaW0tPRIImhpaaGwsJC2tjb27dvH7Nmzeeihh6iqqqKurq7bbqx7KyITQXpCNNV2+agxJox8Ph/PPvssd999N5MnT2bKlCm8++67BAIBbr75ZiZOnMjUqVP5xje+QVpaGpdffjnPP/+8NRaHitNYbGcExpjwuO+++45ML1269GPL33nnnY/NGz16NOvXr/cknog8I0hLiKGxpY3GlkC4QzHGmLCLyETQ3s2ENRgbY0yEJoL2u4utesiYyKKq4Q7Bc8fzHiMyEWQlxwJwsKYxzJEYY/pKXFwc5eXlJ3UyUFXKy8uJi4s7ptdFZGPxsIwEAPaUHw5zJMaYvpKXl0dRURGlpaXhDsVTcXFx5OXlHdNrIjIRZCXFkhDjZ3d5fbhDMcb0kejoaAoKCsIdRr8UkVVDIsKwjER2l1kiMMaYiEwEAAWZCVY1ZIwxRHAiGJaRyL7Kw7QG2sIdijHGhJWniUBE5ojIFhHZLiL3dLL8XBGpFpG17uNeL+MJVpCRSEtAOVBlVw4ZYyKbZ43FIuIHHgUuBIqAlSKySFU3dlh1mape5lUcXWm/cmh3eT1D3WljjIlEXp4RzAS2q+pOVW0Gngau9HB7xyQ/MxHArhwyxkQ8LxPBYGBf0PMid15HZ4jIOhF5WUTGexjPUQYmxxIf7Wd3mTUYG2Mim5f3EUgn8zre0rcGGKaqdSJyCfACMOpjBYncBtwGMHTo0NAEJ8KwjAQ7IzDGRDwvzwiKgCFBz/OAA8ErqGqNqta504uBaBHJ7FiQqi5Q1RmqOiMrKytkAQ4dkEBRpZ0RGGMim5eJYCUwSkQKRCQGuB5YFLyCiOSIiLjTM914yj2M6SiD0uLZX9lwUvc9Yowxn8SzqiFVbRWRO4BXAT+wUFULReR2d/l84NPAV0SkFWgArtc+PCoPTounvjlATWMrqfHRfbVZY4zpVzzta8it7lncYd78oOlHgEe8jKE7g9PjAdhf2WCJwBgTsSL2zmJwqoYADlQ1hDkSY4wJnwhPBE6f3QeqLREYYyJXRCeCzMRYYqJ87K+0RGCMiVwRnQh8PmFQahz7rWrIGBPBIjoRgNNOYG0ExphIZokgLd7OCIwxES3iE8HgtHgO1TbR3GrjEhhjIpMlgrR4VOFgjY1LYIyJTBGfCNrvJSiyK4eMMREq4hNBXnp7IrDO54wxkSniE8GgtHh8AvsqLBEYYyJTxCeCmCgfuanx7LOqIWNMhIr4RAAwZEA8e+2MwBgToSwRAEPSE6xqyBgTsSwRAEMGJHCotonGlkC4QzHGmD5niQBnyEqwK4eMMZHJEgFOGwHAvgprMDbGRB5LBDhVQ4A1GBtjIpIlAiArKZa4aJ81GBtjIpIlAkBEGJKeYGcExpiIZInANSwjgc0ltahquEMxxpg+ZYnAddG4HPZWHGbN3spwh2KMMX3KEoHrkkm5JMT4eWZlUbhDMcaYPmWJwJUUG8Vlk3L5x/oD1De1hjscY4zpM54mAhGZIyJbRGS7iNzTzXqnikhARD7tZTyf5DMzhlDfHOC1jQfDGYYxxvQpzxKBiPiBR4G5wDjgBhEZ18V6DwKvehVLT00fms6AxBje3loa7lCMMabPeHlGMBPYrqo7VbUZeBq4spP17gSeAw55GEuP+HzC2aMyWbatlLY2u3rIGBMZvEwEg4F9Qc+L3HlHiMhg4CpgfncFichtIrJKRFaVlnr7a/1To7Ioq2tmY3GNp9sxxpj+wstEIJ3M6/gz+xfA3arabbefqrpAVWeo6oysrKxQxdeps0dnAlj1kDEmYniZCIqAIUHP84ADHdaZATwtIruBTwO/EpF5Hsb0iQYmxzEuN4WllgiMMRHCy0SwEhglIgUiEgNcDywKXkFVC1Q1X1XzgWeBf1fVFzyMqUdm5KdTeKDG7jI2xkQEzxKBqrYCd+BcDbQJeEZVC0XkdhG53avthsKwjETqmlqpqG8OdyjGGOO5KC8LV9XFwOIO8zptGFbVW7yM5VgMc7ul3lNxmIyk2DBHY4wx3rI7izuRn+mOT1BuvZEaY05+lgg6kZeegAjssURgjIkAlgg6ERftJycljj0V9eEOxRhjPGeJoAtDByRY1ZAxJiJ8YiIQkYdEJEVEokXkDREpE5Gb+yK4cBqWkcBuSwTGmAjQkzOCi1S1BrgM5yax0cC3PY2qHxiWkUhZXZN1SW2MOen1JBFEu38vAZ5S1QoP4+k3hmW4Vw7ZOMbGmJNcTxLB30VkM053EG+ISBbQ6G1Y4TdsQCJgVw4ZY05+n5gIVPUe4Axghqq2APV03p30SaX9XoIdpXVhjsQYY7zVk8bizwCtqhoQke8BTwCDPI8szJLjohmcFs+2g7XhDsUYYzzVk6qh/1LVWhE5C7gY+APwa2/D6h9GZyexucQSgTHm5NaTRNA+VsClwK9V9UUgxruQ+o/ROcnsLK2nJdAW7lCMMcYzPUkE+0XkMeBaYLGIxPbwdSe8MdnJNAfa2FNudxgbY05ePTmgX4vTlfQcVa0CBhAB9xEAjMlJBrDqIWPMSa0nVw0dBnYAF4vIHcBAVf2n55H1AyOykvAJbLVEYIw5ifXkqqGvAX8GBrqPJ0TkTq8D6w/iov3kZyayxa4cMsacxHpSNfQF4DRVvVdV7wVOB77kbVj9x5jsZJZsKWXWA2/y+saD4Q7HGGNCrieJQPjoyiHcafEmnP7nMzPymFkwgOqGFhZ/WBzucIwxJuR6MlTl74EVIvK8+3we8DvPIupnzhubzXljs/nyn1axem9luMMxxpiQ60lj8c+AW4EKoNKdfsbjuPqdaUPT2VN+mLK6pnCHYowxIdWjwetVdQ2wpv25iOwFhnoVVH80bVg6AGv2VHLR+JwwR2OMMaFzvDeGRUwbQbuJg1OJ9gtr9laFOxRjjAmp400EGtIoTgBx0X7GDUplzR5rJzDGnFy6rBoSkf+j8wO+AGk9KVxE5gC/BPzAb1X1gQ7LrwTuB9qAVuDrqvpOjyIPg+lD0/nzij00tgSIi/aHOxxjjAmJ7toIVh3nMgBExA88ClyIM8TlShFZpKobg1Z7A1ikqioik3Aaocd+ctjhcc6YLBb+axfvbCvjgnHZ4Q7HGGNCostEoKp/6GXZM4HtqroTQESexhnQ5kgiUNXgUV8S6edVTmcMzyA5NorXNh60RGCMOWl42YvoYGBf0PMid95RROQqdyjMl4DPd1aQiNwmIqtEZFVpaaknwfZETJSPc8cO5PVNBwm09eucZYwxPeZlIujsyqKPHT1V9XlVHYtzo9r9nRWkqgtUdYaqzsjKygptlMfoonHZlNc3s8ZuLjPGnCR60uncrJ7M60QRMCToeR5woKuVVXUpMEJEMntQdticOyaLGL+PF9fuD3coxhgTEj05I/i/Hs7raCUwSkQKRCQGuB5YFLyCiIwUEXGnp+GMfFbeg7LDJjkumnlTB/Hs6iIq65vDHY4xxvRad5ePngGcCWSJyDeDFqXgXA7aLVVtdccveNVdf6GqForI7e7y+cA1wGdFpAVoAK5T1X5f+f7Fs4fzzKoinnhvD3eePyrc4RhjTK90d/loDJDkrpMcNL8G+HRPClfVxcDiDvPmB00/CDzY02D7i9HZyZw7Jos/LN/NV84dQZQ/IkbuNMacpLq7fPRt4G0ReVxV9wCIiA9IUtWavgqwv5o7IYclW0o5UNXI0IyEcIdjjDHHrSc/ZX8kIikikohzD8AWEYmIMYu7MyTdOfgXVR4OcyTGGNM7PUkE49wzgHk41TxDgX/zMqgTQd6RRNAQ5kiMMaZ3epIIokUkGicRvKiqLfTzO4D7Qm5aHD6xMwJjzImvJ4ngMWA3ThcQS0VkGE6DcUSL9vvITY1nn50RGGNOcJ84MI2qPgw8HDRrj4jM9i6kE8fg9Hg7IzDGnPB6cmdxtoj8TkRedp+PAz7neWQngLz0eGsjMMac8HpSNfQ4zk1hg9znW4GvexTPCWVIegIlNY00t7aFOxRjjDluXSYCEWmvNspU1WdwBo9BVVuBQB/E1u/lpcejCsXVdlZgjDlxdXdG8L77t15EMnCvFBKR04FqrwM7EbRfQrqvwhKBMebE1V1jcXs30t/E6SxuhIj8C8iih11MnOzy0uMBu4TUGHNi6y4RBHc29zzOzWQCNAEXAOs9jq3fy02Nw+8T9lkiMMacwLpLBH6cTuc6DjBjHeu4ovw+xmQn8/6uinCHYowxx627RFCsqv/TZ5GcoC4an80v39hGaW0TWcmx4Q7HGGOOWXeNxZ0NNWk6mDMhB1V4bePBcIdijDHHpbtEcH6fRXECG5OdTH5GAq8UloQ7FGOMOS5dJgJVtYrvHhARLp6Qw7vby9hXYY3GxpgTjw2tFQI3nzaM+Gg/dzy5xu4yNsaccCwRhMCQAQn8+DOTWFdUzSNvbQ93OMYYc0wsEYTInAm5nDE8gzc2WaOxMebEYokghE7NT2dzSS31Ta3hDsUYY3oschJBXSm89C1o9G5MnanD0gm0KeuKqjzbhjHGhFrkJILdy2DVQnjsbCj2pneMaUPSAfhgb5Un5RtjjBc8TQQiMkdEtojIdhG5p5PlN4nIevfxrohM9iyYCVfDrS9DSwMs/rYnm0hNiGbkwCRW76n0pHxjjPGCZ4lARPzAo8BcYBxwgzu6WbBdwDmqOgm4H1jgVTwADD0Npt4MRSuh0ZuetKcPTWfN3kpU1ZPyjTEm1Lw8I5gJbFfVnaraDDwNXBm8gqq+q6rtP5/fA/I8jMcx4jzQAOx+x5Pipw9Lp+pwC8t3lHtSvjHGhJqXiWAwsC/oeZE7rytfAF7ubIGI3CYiq0RkVWlpae+iypsJ0Ymw483eldOFSyflMiwjgW8/u57qhhZPtmGMMaHkZSLorNO6TutLRGQ2TiK4u7PlqrpAVWeo6oysrKzeRRUVA/lnwY63eldOFxJjo/jFdVMoqWnk239dR2vA7jQ2xvRvXiaCImBI0PM84EDHlURkEvBb4EpV7Zv6lBGzoWIHVO7xpPipQ9P53qWn8M+NB7n7uQ+tvcAY0695mQhWAqNEpEBEYoDrcYa8PEJEhgJ/A/5NVbd6GMvRRl3k/N3SaU1USNw6q4A7zxvJc2uKWGED1xhj+jHPEoGqtgJ3AK8Cm4BnVLVQRG4Xkdvd1e4FMoBfichaEVnlVTxHyRgBA8fBpkWfvG4vfPGs4QB2Oakxpl/rboSyXlPVxThjHQfPmx80/UXgi17G0KVTLoe3H4K6Q5A00JNNpCZEMzwzkbX7qjwp3xhjQiFy7izu6JQrAIXNL3m6mSlD0li7r8raCYwx/VbkJoLs8ZBeAOufAQ8P0lOGplFa28SB6kbPtmGMMb0RuYlABE67Hfa+C9vf8GwzU4akAbDW+h8yxvRTkZsIAGZ8HtLz4bV7oS3gySbG5qQQE+Xjg73WYGyM6Z8iOxFExcD534dDhbDuKU82ERPlY3JeKq9uLLFxCowx/VJkJwKA8VfB4Onw5g+h2ZvB5//fRWMoqmzgv/9e6En5xhjTG5YIRODC+6H2ALz3K082cfrwDO6YPZJnVhXx3k7rjM4Y079YIgDInwVjLoWlP4GybZ5s4quzRxIf7ecf6z/Wy4YxxoSVJYJ2l/4UouPgb1+CQOh7DY2L9nPO6Cxe23iQtja7p8AY039YImiXkguX/QIOfODcceyBi8Znc7CmycY0Nsb0K5YIgo2fB5NvhGU/gb0rQl78+WOzifIJj761g/9dvInS2qaQb8MYY46VJYKO5j4IqXnw/G3QVBfSolMTopk1MpPXNx1kwdKdPPb2jpCWb4wxx8MSQUdxKXDVY85YBa9/P+TF//y6KSy+62wumZjDs2uKaGzx5kY2Y4zpKUsEnRl2JpzxVVj525CPZDYgMYZxg1K4+fRhVB1u4aX1xSEt3xhjjpUlgq6c9z3IHA0v3gGN1SEv/ozhGQzPSuTPK7wZJc0YY3rKEkFXouNh3nyoLYaX7wl58SLC9acOYc3eKnaX1Ye8fGOM6SlLBN3Jmw6f+hasexJWPx7y4q+YPBgReGHt/pCXbYwxPWWJ4JOcczeMvABe+hbsfDukReekxnHG8Axe+GC/DVxjjAkbSwSfxOeHa37rjHP858/Apn+EtPh5Uwezu/wwH9hwlsaYMLFE0BPx6XDry5AzEf76Odi3MmRFz5mQQ5RP+GfhwZCVaYwxx8ISQU8lDICbn4WUQfDXW+BwRUiKTYmLZkZ+Oku2HALgpfXFdsexMaZPWSI4FvHpcO0fof4QLP5WyIo9Z/RANpfUsvjDYr765BoW/mtXyMo2xphPYongWA2aCmd9EzY8BzuXhKTIc8dkAXD3s+sBWG+d0hlj+pAlguNx1tedsY4Xfxtam3td3NicZLJTYqltaiUu2sf6omrrqtoY02c8TQQiMkdEtojIdhH52F1ZIjJWRJaLSJOIhK6uxWvR8XDJT6BsKyx/pNfFiQjnjc0mIcbPXeePoraxlT0V3gybaYwxHXmWCETEDzwKzAXGATeIyLgOq1UAdwE/8SoOz4y6EMZe5oxdULW318V955KxvHTX2Zw7eiBg1UPGmL7j5RnBTGC7qu5U1WbgaeDK4BVU9ZCqrgRCPyRYX5jzgDPm8Qv/DoHWXhWVEhdNQWYio7OTiI3ysW5f6Ps3MsaYzniZCAYD+4KeF7nzjpmI3CYiq0RkVWlpaUiCC4m0IU4V0e5l8Ob9ISkyyu9j/KAUOyMwxvQZLxOBdDLvuFpAVXWBqs5Q1RlZWVm9DCvEpt4E02+Ff/0CNi4KSZGTh6SxvqiaVwtLQlKeMcZ0x8tEUAQMCXqeBxzwcHvhM/dBGDzdqSIq3drr4r78qRGMzU3my39azXOriwDnRrOtB2t7XbYxxnTkZSJYCYwSkQIRiQGuB0Lzk7m/iYp1bjSLioUnr4Xa3nUXkZMax19vP4Mx2ck89f5eKuqbuevpD3jolS0hCtgYYz7iWSJQ1VbgDuBVYBPwjKoWisjtInI7gIjkiEgR8E3geyJSJCIpXsXkqdQ8uPEvUHcQ/nwNNPXu13tslJ+5E3NYvbeSJ1fsIdCmvLeznJZAW4gCNsYYh6f3EajqYlUdraojVPWH7rz5qjrfnS5R1TxVTVHVNHe6xsuYPJU3A679ExwsdEY262XX0heOy0YVHn5zOz6BuqZW1lovpcaYELM7i0Nt1AVwwX2w8QV49+FeFTUuN4XBafE0t7bxb6cPwyewbGs/umrKGHNSsETghTPvgvFXwWvfh8IXjrsYEeHCcdkAXD9zKFOGpLF0W1mIgjTGGIclAi+IwLxfw5CZ8LfbYM/y4y7qq7NH8svrpzA2J5mzR2WxvqiKh9/YRm3jiXkPnjGm/7FE4JXoeLjhaeems6dvgLJtx1VMVnIsV04ZjIjw2TOGMXvMQH722lbueuqDEAdsjIlUlgi8lDAAbnoWfFHOMJcNlb0qLiMplt/dcir/MWcMb20pZfWe3pVnjDEAcqINmj5jxgxdtWpVuMM4NntXwOOXwvBz4MZnnHGQe+FwcytnP/gWeenxZCXHUVLTQG5qPD+YN4HslLgQBW2MOZmIyGpVndHZMjsj6AtDT4NLHoLtr8Or/9nry0oTYqL4yrkjWFdUzbqiKrKSYlm2rZTvPv8hJ1piN8aEX1S4A4gYMz7vtBO89ytn3ONZX+tVcZ+fVcC0YelMHJxKtN/Hb5ft5AcvbeLv64u5YvKgEAVtjIkEdkbQly76IYy/Gl67F977da+K8vmEaUPTifY7H+GtswqYPCSN//zbhxQesC6sjTE9Z4mgL/l8cPUCOOUKeOUeePMH0BaaLiP8PmH+zdNIjovi1t+vpKS6EVVlc0mNVRcZY7pliaCv+aPh0wth6s2w9MfOpaX1oblJLDc1nsdvnUltYyv/8dx6/rh8D3N+sYw/r+j9CGrGmJOXJYJw8EfDFY/A3Idgx5vwq9Nh7VPQFuh10WNykvnOJWNZurWU7y8qBOD5D/b3ulxjzMnLEkG4iMBpX4bbljg9l75wOzw6E5b+BBqqelX0zacNY/aYLEZnJ3H7OSNYvaeSfRWHeXPzQb729Afc9dQHBNqsusgY47D7CPoDVaeTuhULYO+7kD0B/u15SBp43EW2tSltqpTUNHLWg28xPCuRnaX1JMdGUdvUyn2Xj+OWWQWhew/GmH7N7iPo70ScTuo+/7KTACp2wu/nQnXRcRfp8wlRfh956Qmcmp/OztJ6vnR2AWvuvZCzR2Xyk39upaS6MYRvwhhzorJE0N+MOA9u/hvUHYKFc6F8R6+LfOCaSSy8ZQbfvXQc0X4fP5g3gda2Nr78xGrW7K3k/J8u4a6nPuBQTSOtNvCNMRHHqob6qwMfwJ+udhqWP/siDDwlpMW/WljCV55YTZtCRmIMtY2tNLtJ4NoZeTxw9SR8PkFVKa5uJDc1DhEJaQzGmL7TXdWQ3VncXw2aCrcuhj/Og4UXw/n3wvRbe91PUbuLx+fw409PZvGHxfzwqonUN7fy8ofF7K04zDOrivD7hP+5cgK/eH0rj761g+FZiRRkJNLYGuBLZw/n3DHH335hjOlf7Iygv6vYBYvuhN3LIGMknHEHjLvS6dnUIw+9splfLdnBkAHx7Kto4IJTsmloaaWivoXaxhaKKhu4csogvnHBaP68Yg+FB2pIT4hhY3ENqfHRPHrTNHJT4lhXVMW/tpcxNieF2WMH4vcJ+6saWLa1lIykWHJT4xiakUBKXHSXsTS2BHj+g/2cN3agdahnTC90d0ZgieBEoAqbFjmXlpasB/FDwdkw9jLnkZIb8k2+sqGE+xYVMjEvlV/fNI0otyuLptYAv16yg0ff2k5LQBGBiYNTqW5oYdTAJFbsqiA2yoeIUFrbdKS8rORYZgxL560th2hs+agdwu8Tzh87kAGJMRyqbeKLZxVw5shMAJpb27j9idW8ufkQcdE+Lh6fQ3JcFFsP1qGqzJmQy6UTc8lJ7VmC2FdxmGi/72PrN7YEWLm7gh2H6rhs8iAyk2K7LUdVUXUa5IOVVDdS3dDCmJxkNuyv5hevb+O+K8aRl54AQGV9M1F+IbmbxGeMVywRnCxUYf8a2Px32PQPKHcHu8k/27knYfRc8Ieutq+tzTnQd9Y2sP1QLX9cvodPT89jUl7akfmbS2r4rxc2MDA5jgvHZXPWqExW7a7g7+uLeX9XBTOGpfO1C0bR2NJGcVUDa/dV8dyaIlrblBi/j0O1TQxOiwegoSVARX0z3754DNsP1bFiZzl1Ta0Mz0qiqbWNTcU1iMCg1HhK65oYl5vCacMHUNPQQkp8NJmJsZTVNXFKbgqxUT6+/pe1tATaOK0gg8RYP4PS4hmcFs9vlu2irM5JWplJMdx/5QTOHp3Ft/+6jre2HCI7JY6clDjiov0cqGrgQFUDAVVOzR/AbZ8azpicZL7yxJoj40N866LR/HV1EXvKD3NKbgrfumg0T7y3h6XbykiM8fNfl41jcHo8e8oPs7fiMJdOzGXC4NSgj1nZsL+G/VUN7C6v51/by5g4OJWrpw1m+Y5yYqP8TM9PZ0RWEgD1Ta0s21ZGZlIM04am85dV+1i5q4LmQBsXjc9h7oScI31SdeZAVQOvFpbQpjBnQg6D0+JpcduLunsdOMnt9+/u5tKJuYzJSQbgB//YyLJtZdx7+ThmjcxEVXl7aykTB6eSkRTLki2HGDoggeFu/ACBNsUflFh3lNYRG+U7kkTBSdhx0aGpGj0exdUNDEyOOyrOE4klgpPVoc3OmcKaP0L1PkgdAqd+EaZ91tOqo1Br/w42tbbx+3/tZtvBWkQEvw9mjczkyimDO33djtI6/rGumJ1ldWQkxrJiVzmbS2pJT4ihpqGF5kAbUT6h1b15bvKQNM4amcGSLaW0Kewuq6ehJcCMYel8dfZI0hNjuOe59WwuqSU+2k9Ta4DPTB9CQ0uA4uoGGlvaGJQWx6C0eNralNc3HWJ/VQMZiTE0tAS46/xRfLC3klcLD+ITuPO8Ufzfm9toUxiYHMvV0/J4f1c5a/ZWHfU+ROD8sdnkZyTg9wsrd1Uctc7wrER2ldV/rPfyT43OIj7ax5ItpTS1Ogfu3NS4I437gTY9kljvPG8ks0ZmUtPYwttbS1F1ztJS4qL47vMbKK9vBiAnJY6vXzCKHy7eRLTfx1VTB3PdqUOI9vtYs6eSXWX1tKmSmxZPZmIMP351CzvL6vEJXHfqUCYMTuG7z28gKTaKuqZWrp46mLgYP0+u2EtBZiIXj89h/ts78PuEuRNyGJAYw/u7Kth+qI5zx2RxwSnZ1DW18uArm4n2+/jR1RO5dGIujy3dyU//uYUvnT2cW2bl8/KHJdQ0thDt95GVFMuF47JJT4wBoLS2id3l9UzOS6OpNcCG/TXsKqvn/V3l7Kk4zNwJOVw7YwhpCTEs31FOSU0Dp+SmsLm4lhW7ytl2sI4rpgzihplDifb7UFUWLN3Jj17ezPljB/LIjdOIj/Ef+e4WHqjhQFUD8TF+Zo3IPHKmqKo88d4eHn93N/99xQTG5iazbFsp543JJjUhmqbWAK9sKMEnwmWTcik8UMOh2kbOG5t9/P9M3bBEcLILtMLWl2HFY05bQlQcjLzA6dxu9MUQnxbuCPuMqiIiBNqUuqZWkmOjWLa9jLV7q/jSpwpIiPnojKmpNUBRZQPDMxOPnPW0BNr4+7oD/G3Nfr5wdgGzu2kUb2wJ8MOXNvHm5kM8cuNUpg5Np6k1wH+9sIFxuSncMquAVzYUU9cU4PLJucRG+WkNtPHO9jJionzkpSWQGh/N/725jdc3HaSkphFVGJQWz62z8pk+LJ2s5FgGJsdReKCaVbsrOWtUJgK8UljC75btIsovzBmfw8UTcijcX8OrhSXceNpQrpo6GFV4a8shHn5jG+uKuu6RdlhGAvNvnk5LoI3PLXyfysMtnJKbQkFmAq9tPEhL4KNjhN8nCBxJrqnx0fzs2sm8s72MPy3fQ2ubMjkvlSe+eBqPvb2Tx5buoCWgXDMtj1cLS6hrauXyyYPISIzhpQ+LaWwJMDo7mXG5KfxzYwkHa5wzs9ljsqhpbGX1nkpi/D6aA22MzUlmc0ltp+8hLSGaa6blUVLTyGuFB2kOtJEY46ehJUD7TfSZSTHkpsbz4f5qMhJjmD12IM+uPvpeneS4KAalxrPlYC0jshK5e85YXlx3gJfWFzNtaBof7KtieGYinxqdRWV9Myt2VVAcdD/O5LxUTs0fQHl9M3srDrN6TyWJMX6aWtuIi/ZT19RKRmIMp+YPYMWucioPO2OPj81JZsvBWlThuhlDKKlppLi6ga/OHsmcCTmowpq9lWQlxTIqO7nLz7I7YUsEIjIH+CXgB36rqg90WC7u8kuAw8AtqrqmuzItEXyCg4Ww+nGn6qj2gNOeMGA4ZI6GzJHOWUNyDiQPcs4aEjMh9vi+WCa82v93P+myXlVl9Z5Kth2qw+8Tzhs7kKTYKIqrG9lZWseMYQNITXDaLbaU1PLKhpIjSbO8romXPixGRDitYAAFmYn4RCira+JAVQNDBiQcaVPZWVrHU+/v5XNn5h+p0tl+qI59lYeZPWYgG/ZXs3xHOZ8/q6DT6hVVZVdZPYdqm5iZP4CAKos/LGbdvmpGDEzkxplD+euqInaW1XP9qUMYOiCB5kAbWw/W8r+LN/H+rgqyU+I4/5SBnDE8k+U7yxiQ6LRNDc9KZFBqPD6fsGF/Nf/5/IesL6rmuhlDuPn0YWw9WMvY3GTG5qTgE3hz8yHufbGQ/VUNxEb5uGP2SL46eyRvbD7EY2/vYL2bTCbnpXHhuGzGuEnq569tpaK+mYykGDISY5gzIZcbTxvK3c+uR1GunTGEBUt3sr+qgVPzB3DV1MHsrTjMz17bymWTcon2+/jdO7vISIwhMymWLQdrEYEon9ASUG45M5/7rhh/XN+XsCQCEfEDW4ELgSJgJXCDqm4MWucS4E6cRHAa8EtVPa27ci0R9FBbGxxYA1tfhdJNzqA4FTsh0PzxdRMyIL0ABhR89Dd1CMQmQXQCRMU6HeJpG7S1Og/xQ3QcRMV/9Dcq1qnnCI6h5TA01zuviUuBmKSj1+moqc5ZH5wzmahuGm4DrRBogtYmCLQ4l9b6o8Ef4zx8fqddRRVQQHAbPY5jh4ZRS4P7/qIgJuGT1w+1I/sQwOtpgj6v9m23QVQMxKZ0e/l0W5t+rAG/K62BNraX1jEmO7nLRFrf1MrzH+zn3DFZR7VVOGFpp6/rav6x2FRcw7CMBGKj/Ly+6SCbimtoaAlwWsEATs0fcNwXG4QrEZwB3KeqF7vPvwOgqj8KWucxYImqPuU+3wKcq6rFXZVriaAX2gJOl9e1xVBbAg0VUHfQuUS1chdU7na6tdDjvbtYINpNCK1NThL42Cp+Jxmgbm+rCuJz5msAmuuOXj82BeLSnJgCTdDa7PwNNPcizqB4wU0M4sbRPi0fLdc2JzZwDsa+aGdsieD1Ovsr7jq4BzNtc95zW+CjhKoBp0x/rHOwO7K9Nucg2NoErQ0fhdyecNEjx0rPDs79UWyKU/XZ/pm076cj+yz4O9Hh8z0y7S4Lnj7ypyfr9bS89vXUSeYtDdDa6H43/M73w+d3pn2+j/4PjszzH72u+GD6LXDmHce168J1Q9lgYF/Q8yKcX/2ftM5g4KhEICK3AbcBDB06NOSBRgyfH5KznUdXWpudhufqfe6X9zC0NDqv9UV99CXVgDO/tcH523LY+ZK3NDgHr6hY54Afk+g8fH5orIHGKucXf/sXGz76RxZxOtqLTXGeN1ZBfTk0VLq/9mOccoP/HpmOdsoJNLuPFudAG3yAb99Opwc/7WS5u077PyK4B3D3QN7xtZ3+bQt6r+Lux+ij92egxYm5temjBNL+8EdDfLqTKALNcLjcWR86OSB1PDh90jqhmCZE5XQyLUHPW5uhsdr5TrQ2Hn1wbH8EJ+euzjbg42ccH1tPQ7Re0Daj4z/6kXQkcQU+OtNu/5FwZF7AWe/ItJvwkrxpSPYyEXR2ftTxZ0ZP1kFVFwALwDkj6H1opktRMZAxwnkYYyKCl53OFQFDgp7nAQeOYx1jjDEe8jIRrARGiUiBiMQA1wOLOqyzCPisOE4HqrtrHzDGGBN6nlUNqWqriNwBvIpz+ehCVS0Ukdvd5fOBxThXDG3HuXz0Vq/iMcYY0zlPex9V1cU4B/vgefODphX4qpcxGGOM6Z4NTGOMMRHOEoExxkQ4SwTGGBPhLBEYY0yEO+F6HxWRUmDPcb48EygLYTih1F9js7iOTX+NC/pvbBbXsTneuIapalZnC064RNAbIrKqq742wq2/xmZxHZv+Ghf039gsrmPjRVxWNWSMMRHOEoExxkS4SEsEC8IdQDf6a2wW17Hpr3FB/43N4jo2IY8rotoIjDHGfFyknREYY4zpwBKBMcZEuIhJBCIyR0S2iMh2EbknjHEMEZG3RGSTiBSKyNfc+feJyH4RWes+LglDbLtF5EN3+6vceQNE5DUR2eb+TQ9DXGOC9staEakRka+HY5+JyEIROSQiG4LmdbmPROQ77ndui4hc3Mdx/VhENovIehF5XkTS3Pn5ItIQtN/md1mwN3F1+bn11f7qJra/BMW1W0TWuvP7ZJ91c3zw9jumqif9A6cb7B3AcCAGWAeMC1MsucA0dzoZ2AqMA+4DvhXm/bQbyOww7yHgHnf6HuDBfvBZlgDDwrHPgE8B04ANn7SP3M91HRALFLjfQX8fxnUREOVOPxgUV37wemHYX51+bn25v7qKrcPynwL39uU+6+b44Ol3LFLOCGYC21V1p6o2A08DV4YjEFUtVtU17nQtsAlnnOb+6krgD+70H4B54QsFgPOBHap6vHeX94qqLgUqOszuah9dCTytqk2qugtn3I2ZfRWXqv5TVVvdp+/hjADYp7rYX13ps/31SbGJiADXAk95tf0uYurq+ODpdyxSEsFgYF/Q8yL6wcFXRPKBqcAKd9Yd7mn8wnBUweCMF/1PEVktIre587LVHTXO/TswDHEFu56j/znDvc+g633Un753nwdeDnpeICIfiMjbInJ2GOLp7HPrT/vrbOCgqm4Lmten+6zD8cHT71ikJALpZF5Yr5sVkSTgOeDrqloD/BoYAUwBinFOS/vaLFWdBswFvioinwpDDF0SZ8jTK4C/urP6wz7rTr/43onId4FW4M/urGJgqKpOBb4JPCkiKX0YUlefW7/YX64bOPoHR5/us06OD12u2sm8Y95nkZIIioAhQc/zgANhigURicb5kP+sqn8DUNWDqhpQ1TbgN3h4StwVVT3g/j0EPO/GcFBEct24c4FDfR1XkLnAGlU9CP1jn7m62kdh/96JyOeAy4Cb1K1UdqsRyt3p1Tj1yqP7KqZuPrew7y8AEYkCrgb+0j6vL/dZZ8cHPP6ORUoiWAmMEpEC91fl9cCicATi1j3+Dtikqj8Lmp8btNpVwIaOr/U4rkQRSW6fxmlo3ICznz7nrvY54MW+jKuDo36lhXufBelqHy0CrheRWBEpAEYB7/dVUCIyB7gbuEJVDwfNzxIRvzs93I1rZx/G1dXnFtb9FeQCYLOqFrXP6Kt91tXxAa+/Y163gveXB3AJTgv8DuC7YYzjLJxTt/XAWvdxCfAn4EN3/iIgt4/jGo5z9cE6oLB9HwEZwBvANvfvgDDttwSgHEgNmtfn+wwnERUDLTi/xr7Q3T4Cvut+57YAc/s4ru049cft37P57rrXuJ/xOmANcHkfx9Xl59ZX+6ur2Nz5jwO3d1i3T/ZZN8cHT79j1sWEMcZEuEipGjLGGNMFSwTGGBPhLBEYY0yEs0RgjDERzhKBMcZEOEsExnQgIgE5urfTkPVW6/ZiGa77HYzpVFS4AzCmH2pQ1SnhDsKYvmJnBMb0kNs//YMi8r77GOnOHyYib7idqL0hIkPd+dnijAOwzn2c6RblF5HfuP3N/1NE4sP2pozBEoExnYnvUDV0XdCyGlWdCTwC/MKd9wjwR1WdhNOx28Pu/IeBt1V1Mk6/94Xu/FHAo6o6HqjCuWvVmLCxO4uN6UBE6lQ1qZP5u4HzVHWn2zFYiapmiEgZTjcJLe78YlXNFJFSIE9Vm4LKyAdeU9VR7vO7gWhV/UEfvDVjOmVnBMYcG+1iuqt1OtMUNB3A2upMmFkiMObYXBf0d7k7/S5Oj7YANwHvuNNvAF8BEBF/H/f5b0yP2S8RYz4uXtxBy12vqGr7JaSxIrIC50fUDe68u4CFIvJtoBS41Z3/NWCBiHwB55f/V3B6uzSmX7E2AmN6yG0jmKGqZeGOxZhQsqohY4yJcHZGYIwxEc7OCIwxJsJZIjDGmAhnicAYYyKcJQJjjIlwlgiMMSbC/X+74s5nE0BuEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_RNN_VZ.history['loss'])\n",
    "plt.plot(history_RNN_VZ.history['val_loss'])\n",
    "plt.title('RNN model Loss')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3663aaa",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97042e8f",
   "metadata": {},
   "source": [
    "Now, it is time to apply LSTM. Even though the LSTM is built on RNN, it has different structure in the sense that LSTM include forget gates by which we can surpress the past and unrelated information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57498fe6",
   "metadata": {},
   "source": [
    "Here, I run an LSTM with two hidden layers with 128 and 64 neurons, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c66bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_part():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256,\n",
    "              input_shape=(n_steps, n_features),\n",
    "              return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam' , loss='mean_squared_error',metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f38238b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 2s 366ms/step - loss: 0.4053 - mse: 0.4053 - val_loss: 0.0987 - val_mse: 0.0987\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3901 - mse: 0.3901 - val_loss: 0.0996 - val_mse: 0.0996\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3782 - mse: 0.3782 - val_loss: 0.1003 - val_mse: 0.1003\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3694 - mse: 0.3694 - val_loss: 0.1013 - val_mse: 0.1013\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3617 - mse: 0.3617 - val_loss: 0.1018 - val_mse: 0.1018\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3541 - mse: 0.3541 - val_loss: 0.1019 - val_mse: 0.1019\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3438 - mse: 0.3438 - val_loss: 0.1012 - val_mse: 0.1012\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3377 - mse: 0.3377 - val_loss: 0.0990 - val_mse: 0.0990\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3290 - mse: 0.3290 - val_loss: 0.0961 - val_mse: 0.0961\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3209 - mse: 0.3209 - val_loss: 0.0941 - val_mse: 0.0941\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3139 - mse: 0.3139 - val_loss: 0.0919 - val_mse: 0.0919\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3051 - mse: 0.3051 - val_loss: 0.0913 - val_mse: 0.0913\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.2959 - mse: 0.2959 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2860 - mse: 0.2860 - val_loss: 0.0874 - val_mse: 0.0874\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.2754 - mse: 0.2754 - val_loss: 0.0851 - val_mse: 0.0851\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2637 - mse: 0.2637 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2506 - mse: 0.2506 - val_loss: 0.0796 - val_mse: 0.0796\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2391 - mse: 0.2391 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2249 - mse: 0.2249 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2102 - mse: 0.2102 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1957 - mse: 0.1957 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1879 - mse: 0.1879 - val_loss: 0.0570 - val_mse: 0.0570\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1674 - mse: 0.1674 - val_loss: 0.0533 - val_mse: 0.0533\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.1486 - mse: 0.1486 - val_loss: 0.0458 - val_mse: 0.0458\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1161 - mse: 0.1161 - val_loss: 0.0384 - val_mse: 0.0384\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0894 - mse: 0.0894 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0670 - mse: 0.0670 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0545 - mse: 0.0545 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0385 - val_mse: 0.0385\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0510 - mse: 0.0510 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0438 - mse: 0.0438 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 7.9743e-04 - val_mse: 7.9743e-04\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 9.2364e-04 - val_mse: 9.2364e-04\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 9.4357e-04 - val_mse: 9.4357e-04\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 6.9189e-04 - val_mse: 6.9189e-04\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 5.2265e-04 - val_mse: 5.2265e-04\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 4.2136e-04 - val_mse: 4.2136e-04\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 6.8602e-04 - val_mse: 6.8602e-04\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 4.2463e-04 - val_mse: 4.2463e-04\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 3.7928e-04 - val_mse: 3.7928e-04\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 4.1556e-04 - val_mse: 4.1556e-04\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 8.2027e-04 - val_mse: 8.2027e-04\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 4.9489e-04 - val_mse: 4.9489e-04\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 6.9291e-04 - val_mse: 6.9291e-04\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 3.3933e-04 - val_mse: 3.3933e-04\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.7747e-04 - val_mse: 3.7747e-04\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 2.8706e-04 - val_mse: 2.8706e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.1007e-04 - val_mse: 3.1007e-04\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 3.1213e-04 - val_mse: 3.1213e-04\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 7.5400e-04 - val_mse: 7.5400e-04\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 5.3509e-04 - val_mse: 5.3509e-04\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.1089e-04 - val_mse: 3.1089e-04\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 8.7840e-04 - val_mse: 8.7840e-04\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 3.8053e-04 - val_mse: 3.8053e-04\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.8862e-04 - val_mse: 1.8862e-04\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.4145e-04 - val_mse: 1.4145e-04\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 3.2193e-04 - val_mse: 3.2193e-04\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.6896e-04 - val_mse: 1.6896e-04\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 3.2772e-04 - val_mse: 3.2772e-04\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 4.1377e-04 - val_mse: 4.1377e-04\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.8118e-04 - val_mse: 3.8118e-04\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 3.8648e-04 - val_mse: 3.8648e-04\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.6491e-04 - val_mse: 2.6491e-04\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.1141e-04 - val_mse: 2.1141e-04\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.3655e-04 - val_mse: 2.3655e-04\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 6.5857e-04 - val_mse: 6.5857e-04\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.2896e-04 - val_mse: 2.2896e-04\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.5107e-04 - val_mse: 2.5107e-04\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 3.1415e-04 - val_mse: 3.1415e-04\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.2898e-04 - val_mse: 2.2898e-04\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.4521e-04 - val_mse: 3.4521e-04\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.5578e-04 - val_mse: 2.5578e-04\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.2832e-04 - val_mse: 1.2832e-04\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 4.2644e-04 - val_mse: 4.2644e-04\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.7755e-04 - val_mse: 1.7755e-04\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.0110e-04 - val_mse: 2.0110e-04\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.4097e-04 - val_mse: 2.4097e-04\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 3.3005e-04 - val_mse: 3.3005e-04\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.6490e-04 - val_mse: 2.6490e-04\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.9996e-04 - val_mse: 1.9996e-04\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.1691e-04 - val_mse: 2.1691e-04\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 4.0641e-04 - val_mse: 4.0641e-04\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.2088e-04 - val_mse: 1.2088e-04\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.8612e-04 - val_mse: 1.8612e-04\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.3127e-04 - val_mse: 1.3127e-04\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 5.3150e-05 - val_mse: 5.3150e-05\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 2.9791e-04 - val_mse: 2.9791e-04\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.1831e-04 - val_mse: 1.1831e-04\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 7.9275e-05 - val_mse: 7.9275e-05\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 7.2228e-05 - val_mse: 7.2228e-05\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 6.5581e-05 - val_mse: 6.5581e-05\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.1998e-04 - val_mse: 1.1998e-04\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.2672e-04 - val_mse: 1.2672e-04\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 6.1014e-05 - val_mse: 6.1014e-05\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 4.7946e-05 - val_mse: 4.7946e-05\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 8.1761e-05 - val_mse: 8.1761e-05\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.7015e-04 - val_mse: 1.7015e-04\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.0884e-04 - val_mse: 1.0884e-04\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 8.1932e-05 - val_mse: 8.1932e-05\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.3768e-04 - val_mse: 1.3768e-04\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 2.0327e-04 - val_mse: 2.0327e-04\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.5400e-04 - val_mse: 1.5400e-04\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 7.9508e-05 - val_mse: 7.9508e-05\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 8.8008e-05 - val_mse: 8.8008e-05\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 6.9693e-05 - val_mse: 6.9693e-05\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 2.2047e-04 - val_mse: 2.2047e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.5590e-04 - val_mse: 2.5590e-04\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 8.0666e-05 - val_mse: 8.0666e-05\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 9.5349e-05 - val_mse: 9.5349e-05\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.8570e-04 - val_mse: 1.8570e-04\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 4.7333e-04 - val_mse: 4.7333e-04\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 3.6723e-04 - val_mse: 3.6723e-04\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.5084e-04 - val_mse: 1.5084e-04\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 5.6045e-05 - val_mse: 5.6045e-05\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.7445e-04 - val_mse: 1.7445e-04\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.2908e-04 - val_mse: 1.2908e-04\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 3.5736e-04 - val_mse: 3.5736e-04\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.2356e-04 - val_mse: 1.2356e-04\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 4.9096e-05 - val_mse: 4.9096e-05\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 8.0949e-05 - val_mse: 8.0949e-05\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 8.8825e-05 - val_mse: 8.8825e-05\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.4841e-04 - val_mse: 1.4841e-04\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 1.2018e-04 - val_mse: 1.2018e-04\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 5.5206e-05 - val_mse: 5.5206e-05\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 5.2974e-05 - val_mse: 5.2974e-05\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 5.7236e-05 - val_mse: 5.7236e-05\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.5076e-04 - val_mse: 1.5076e-04\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.8866e-04 - val_mse: 1.8866e-04\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 8.7092e-05 - val_mse: 8.7092e-05\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 5.7134e-05 - val_mse: 5.7134e-05\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.1206e-05 - val_mse: 7.1206e-05\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 7.8234e-05 - val_mse: 7.8234e-05\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 6.1033e-05 - val_mse: 6.1033e-05\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 4.6736e-05 - val_mse: 4.6736e-05\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.7546e-05 - val_mse: 7.7546e-05\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.4040e-04 - val_mse: 1.4040e-04\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.0914e-04 - val_mse: 1.0914e-04\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 6.8992e-05 - val_mse: 6.8992e-05\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 6.5894e-05 - val_mse: 6.5894e-05\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.5924e-05 - val_mse: 7.5924e-05\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.1663e-04 - val_mse: 1.1663e-04\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 9.8921e-05 - val_mse: 9.8921e-05\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 7.6134e-05 - val_mse: 7.6134e-05\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.2386e-04 - val_mse: 1.2386e-04\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 8.7112e-05 - val_mse: 8.7112e-05\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.7097e-04 - val_mse: 1.7097e-04\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 9.8227e-05 - val_mse: 9.8227e-05\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 4.4115e-05 - val_mse: 4.4115e-05\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 4.9905e-05 - val_mse: 4.9905e-05\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.5848e-04 - val_mse: 1.5848e-04\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.4759e-04 - val_mse: 1.4759e-04\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 8.7636e-05 - val_mse: 8.7636e-05\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 2.3550e-04 - val_mse: 2.3550e-04\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 8.8992e-05 - val_mse: 8.8992e-05\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 1.9440e-04 - val_mse: 1.9440e-04\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 1.0886e-04 - val_mse: 1.0886e-04\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 6.1100e-05 - val_mse: 6.1100e-05\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.2962e-04 - val_mse: 1.2962e-04\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 4.9496e-05 - val_mse: 4.9496e-05\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.7325e-04 - val_mse: 1.7325e-04\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.1285e-04 - val_mse: 1.1285e-04\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.1111e-05 - val_mse: 9.1111e-05\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 1.2021e-04 - val_mse: 1.2021e-04\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 7.0732e-05 - val_mse: 7.0732e-05\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 7.7924e-05 - val_mse: 7.7924e-05\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.6349e-05 - val_mse: 7.6349e-05\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 6.7703e-05 - val_mse: 6.7703e-05\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.2256e-04 - val_mse: 1.2256e-04\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 8.6920e-05 - val_mse: 8.6920e-05\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 7.0507e-05 - val_mse: 7.0507e-05\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.1563e-04 - val_mse: 1.1563e-04\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 1.4154e-04 - val_mse: 1.4154e-04\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.2725e-04 - val_mse: 1.2725e-04\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 1.1265e-04 - val_mse: 1.1265e-04\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.2253e-05 - val_mse: 7.2253e-05\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 9.1928e-05 - val_mse: 9.1928e-05\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 2.8290e-04 - val_mse: 2.8290e-04\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.1856e-04 - val_mse: 1.1856e-04\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 3.9449e-05 - val_mse: 3.9449e-05\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 7.9533e-05 - val_mse: 7.9533e-05\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 2.0971e-04 - val_mse: 2.0971e-04\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 1.0577e-04 - val_mse: 1.0577e-04\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 5.2444e-05 - val_mse: 5.2444e-05\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 4.2441e-05 - val_mse: 4.2441e-05\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 8.2538e-04 - mse: 8.2538e-04 - val_loss: 9.9045e-05 - val_mse: 9.9045e-05\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = LSTM_part()\n",
    "history_LSTM = LSTM_model.fit(X_diff_train_T, y_diff_train_T,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3d260dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = X_diff_test_T[X_diff_test_T.shape[0]-1]\n",
    "T_input = start\n",
    "T_input = T_input.reshape((1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d935814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_LSTM_T = []\n",
    "\n",
    "for i in range(len(arima_predictions_T)):\n",
    "    T_input = T_input.reshape((1, n_steps, n_features))\n",
    "    yhat_lstm = LSTM_model.predict(T_input, verbose=0)\n",
    "    T_input = np.append(T_input, yhat_lstm)\n",
    "    T_input = T_input[1:]\n",
    "    predictions_LSTM_T.append(yhat_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c8d6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of AT&T for LSTM model 0.4300\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of AT&T for LSTM model {:.4f}'\\\n",
    "      .format(rmse(diff_test_T, np.array(predictions_LSTM_T).flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f22e560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_LSTM.history['loss'])\n",
    "plt.plot(history_LSTM.history['val_loss'])\n",
    "plt.title('LSTM model Loss')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e6635a",
   "metadata": {},
   "source": [
    "Even though the structure of LSTM is different than that of RNN, it shows a very similar performance, indicating that we do not need very complex structure to model this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "968036a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_part():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,\n",
    "              input_shape=(n_steps, n_features),\n",
    "              return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam' , loss='mean_squared_error',metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b552350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 2s 441ms/step - loss: 0.6201 - mse: 0.6201 - val_loss: 0.2114 - val_mse: 0.2114\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6052 - mse: 0.6052 - val_loss: 0.2095 - val_mse: 0.2095\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5914 - mse: 0.5914 - val_loss: 0.2080 - val_mse: 0.2080\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5822 - mse: 0.5822 - val_loss: 0.2064 - val_mse: 0.2064\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5710 - mse: 0.5710 - val_loss: 0.2050 - val_mse: 0.2050\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5601 - mse: 0.5601 - val_loss: 0.2028 - val_mse: 0.2028\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5511 - mse: 0.5511 - val_loss: 0.2010 - val_mse: 0.2010\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5371 - mse: 0.5371 - val_loss: 0.1988 - val_mse: 0.1988\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5283 - mse: 0.5283 - val_loss: 0.1964 - val_mse: 0.1964\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5168 - mse: 0.5168 - val_loss: 0.1935 - val_mse: 0.1935\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5050 - mse: 0.5050 - val_loss: 0.1907 - val_mse: 0.1907\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4953 - mse: 0.4953 - val_loss: 0.1871 - val_mse: 0.1871\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4838 - mse: 0.4838 - val_loss: 0.1839 - val_mse: 0.1839\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4720 - mse: 0.4720 - val_loss: 0.1803 - val_mse: 0.1803\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4588 - mse: 0.4588 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4485 - mse: 0.4485 - val_loss: 0.1727 - val_mse: 0.1727\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4325 - mse: 0.4325 - val_loss: 0.1685 - val_mse: 0.1685\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4170 - mse: 0.4170 - val_loss: 0.1647 - val_mse: 0.1647\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4013 - mse: 0.4013 - val_loss: 0.1594 - val_mse: 0.1594\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.1529 - val_mse: 0.1529\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3581 - mse: 0.3581 - val_loss: 0.1457 - val_mse: 0.1457\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3358 - mse: 0.3358 - val_loss: 0.1349 - val_mse: 0.1349\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2947 - mse: 0.2947 - val_loss: 0.1201 - val_mse: 0.1201\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2843 - mse: 0.2843 - val_loss: 0.1089 - val_mse: 0.1089\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2544 - mse: 0.2544 - val_loss: 0.1090 - val_mse: 0.1090\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2396 - mse: 0.2396 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2150 - mse: 0.2150 - val_loss: 0.0819 - val_mse: 0.0819\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1898 - mse: 0.1898 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1620 - mse: 0.1620 - val_loss: 0.0685 - val_mse: 0.0685\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1502 - mse: 0.1502 - val_loss: 0.0667 - val_mse: 0.0667\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1353 - mse: 0.1353 - val_loss: 0.0588 - val_mse: 0.0588\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1115 - mse: 0.1115 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1042 - mse: 0.1042 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0890 - mse: 0.0890 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0215 - val_mse: 0.0215\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0468 - mse: 0.0468 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0403 - mse: 0.0403 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0382 - mse: 0.0382 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0323 - mse: 0.0323 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0071 - val_mse: 0.0071\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 8.8218e-04 - val_mse: 8.8218e-04\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 8.6631e-04 - val_mse: 8.6631e-04\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 9.8747e-04 - val_mse: 9.8747e-04\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 9.5091e-04 - val_mse: 9.5091e-04\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 8.0627e-04 - val_mse: 8.0627e-04\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 7.7709e-04 - val_mse: 7.7709e-04\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 8.5856e-04 - val_mse: 8.5856e-04\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 8.1727e-04 - val_mse: 8.1727e-04\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 8.4296e-04 - val_mse: 8.4296e-04\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 9.0601e-04 - val_mse: 9.0601e-04\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 7.8992e-04 - val_mse: 7.8992e-04\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 6.5340e-04 - val_mse: 6.5340e-04\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 8.0143e-04 - val_mse: 8.0143e-04\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 9.6423e-04 - val_mse: 9.6423e-04\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 6.8141e-04 - val_mse: 6.8141e-04\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 9.2816e-04 - val_mse: 9.2816e-04\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 7.0820e-04 - val_mse: 7.0820e-04\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 8.6386e-04 - val_mse: 8.6386e-04\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 8.8206e-04 - val_mse: 8.8206e-04\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 7.9751e-04 - val_mse: 7.9751e-04\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 6.7107e-04 - val_mse: 6.7107e-04\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 6.7136e-04 - val_mse: 6.7136e-04\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 7.0231e-04 - val_mse: 7.0231e-04\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 8.3050e-04 - val_mse: 8.3050e-04\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 9.1329e-04 - val_mse: 9.1329e-04\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 7.6296e-04 - val_mse: 7.6296e-04\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 6.8578e-04 - val_mse: 6.8578e-04\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 5.1565e-04 - val_mse: 5.1565e-04\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 5.3088e-04 - val_mse: 5.3088e-04\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 5.4899e-04 - val_mse: 5.4899e-04\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 6.0925e-04 - val_mse: 6.0925e-04\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 6.0681e-04 - val_mse: 6.0681e-04\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 4.7266e-04 - val_mse: 4.7266e-04\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 3.9652e-04 - val_mse: 3.9652e-04\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 4.7376e-04 - val_mse: 4.7376e-04\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 5.8753e-04 - val_mse: 5.8753e-04\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 6.3301e-04 - val_mse: 6.3301e-04\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 6.3283e-04 - val_mse: 6.3283e-04\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 9.7672e-04 - val_mse: 9.7672e-04\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 4.8846e-04 - val_mse: 4.8846e-04\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 5.1071e-04 - val_mse: 5.1071e-04\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 4.5786e-04 - val_mse: 4.5786e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 5.6019e-04 - val_mse: 5.6019e-04\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 4.1266e-04 - val_mse: 4.1266e-04\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 5.0819e-04 - val_mse: 5.0819e-04\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 4.6534e-04 - val_mse: 4.6534e-04\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 6.7017e-04 - val_mse: 6.7017e-04\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 4.9842e-04 - val_mse: 4.9842e-04\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 4.8812e-04 - val_mse: 4.8812e-04\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 5.6792e-04 - val_mse: 5.6792e-04\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 5.4884e-04 - val_mse: 5.4884e-04\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 4.4772e-04 - val_mse: 4.4772e-04\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 5.1525e-04 - val_mse: 5.1525e-04\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 5.7181e-04 - val_mse: 5.7181e-04\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 6.5284e-04 - val_mse: 6.5284e-04\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 3.9580e-04 - val_mse: 3.9580e-04\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.5261e-04 - val_mse: 3.5261e-04\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 3.3897e-04 - val_mse: 3.3897e-04\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 4.2455e-04 - val_mse: 4.2455e-04\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 3.9071e-04 - val_mse: 3.9071e-04\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 4.2507e-04 - val_mse: 4.2507e-04\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.7614e-04 - val_mse: 3.7614e-04\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 3.7625e-04 - val_mse: 3.7625e-04\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.6049e-04 - val_mse: 3.6049e-04\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 3.0447e-04 - val_mse: 3.0447e-04\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 4.4546e-04 - val_mse: 4.4546e-04\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.9799e-04 - val_mse: 2.9799e-04\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.1481e-04 - val_mse: 3.1481e-04\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.6313e-04 - val_mse: 3.6313e-04\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 3.9256e-04 - val_mse: 3.9256e-04\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.6094e-04 - val_mse: 3.6094e-04\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 3.7174e-04 - val_mse: 3.7174e-04\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 3.8761e-04 - val_mse: 3.8761e-04\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 4.6099e-04 - val_mse: 4.6099e-04\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 3.4308e-04 - val_mse: 3.4308e-04\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.6125e-04 - val_mse: 3.6125e-04\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.7337e-04 - val_mse: 3.7337e-04\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 3.6577e-04 - val_mse: 3.6577e-04\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.9604e-04 - val_mse: 3.9604e-04\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 3.3979e-04 - val_mse: 3.3979e-04\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 3.3778e-04 - val_mse: 3.3778e-04\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 3.2080e-04 - val_mse: 3.2080e-04\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.0839e-04 - val_mse: 3.0839e-04\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 4.4356e-04 - val_mse: 4.4356e-04\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.5975e-04 - val_mse: 3.5975e-04\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.8297e-04 - val_mse: 2.8297e-04\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.2978e-04 - val_mse: 2.2978e-04\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.2392e-04 - val_mse: 2.2392e-04\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.3838e-04 - val_mse: 3.3838e-04\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 4.3206e-04 - val_mse: 4.3206e-04\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.6963e-04 - val_mse: 2.6963e-04\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.5906e-04 - val_mse: 2.5906e-04\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.8203e-04 - val_mse: 2.8203e-04\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 3.5209e-04 - val_mse: 3.5209e-04\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 3.0183e-04 - val_mse: 3.0183e-04\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 2.6192e-04 - val_mse: 2.6192e-04\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.1610e-04 - val_mse: 2.1610e-04\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.5505e-04 - val_mse: 2.5505e-04\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 3.1011e-04 - val_mse: 3.1011e-04\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.2495e-04 - val_mse: 2.2495e-04\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.1452e-04 - val_mse: 2.1452e-04\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.2963e-04 - val_mse: 2.2963e-04\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.4428e-04 - val_mse: 2.4428e-04\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 4.2427e-04 - val_mse: 4.2427e-04\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.8046e-04 - val_mse: 2.8046e-04\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.9258e-04 - val_mse: 2.9258e-04\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.9893e-04 - val_mse: 2.9893e-04\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.0855e-04 - val_mse: 3.0855e-04\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 3.0462e-04 - val_mse: 3.0462e-04\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.4856e-04 - val_mse: 3.4856e-04\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.9398e-04 - val_mse: 2.9398e-04\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.3831e-04 - val_mse: 3.3831e-04\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.5661e-04 - val_mse: 2.5661e-04\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 4.8156e-04 - val_mse: 4.8156e-04\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 3.2989e-04 - val_mse: 3.2989e-04\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.3279e-04 - val_mse: 2.3279e-04\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.5334e-04 - val_mse: 1.5334e-04\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.2569e-04 - val_mse: 2.2569e-04\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 2.9764e-04 - val_mse: 2.9764e-04\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.8015e-04 - val_mse: 1.8015e-04\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = LSTM_part()\n",
    "history_LSTM_VZ = LSTM_model.fit(X_diff_train_VZ, y_diff_train_VZ,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fadb3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = X_diff_train_VZ[X_diff_train_VZ.shape[0]-1]\n",
    "VZ_input = start\n",
    "VZ_input = VZ_input.reshape((1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b4ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_LSTM_VZ = []\n",
    "\n",
    "for i in range(len(arima_predictions_VZ)):\n",
    "    VZ_input = VZ_input.reshape((1, n_steps, n_features))\n",
    "    yhat_lstm = LSTM_model.predict(VZ_input, verbose=0)\n",
    "    VZ_input = np.append(T_input, yhat_lstm)\n",
    "    VZ_input = VZ_input[1:]\n",
    "    predictions_LSTM_VZ.append(yhat_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d493ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of VZ for LSTM model 0.4723\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of VZ for LSTM model {:.4f}'\\\n",
    "      .format(rmse(diff_test_VZ, np.array(predictions_LSTM_VZ).flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5591983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_LSTM_VZ.history['loss'])\n",
    "plt.plot(history_LSTM_VZ.history['val_loss'])\n",
    "plt.title('LSTM model Loss')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
