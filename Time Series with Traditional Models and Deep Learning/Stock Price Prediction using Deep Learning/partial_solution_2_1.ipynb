{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Solution: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code imports the data you generated before for replicating.\n",
    "\n",
    "stock_prices = pd.read_csv('stock_prices.csv')\n",
    "arima_predictions_T = pd.read_csv('arima_predictions_T')\n",
    "\n",
    "diff_T = stock_prices['T'].diff().dropna()\n",
    "\n",
    "split = int(len(diff_T.values)*0.95)\n",
    "diff_train_T = diff_T.iloc[:split]\n",
    "diff_test_T = diff_T.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_diff_train_T, y_diff_train_T = split_sequence(diff_train_T, n_steps)\n",
    "X_diff_train_T = X_diff_train_T.reshape((X_diff_train_T.shape[0],\n",
    "                                         X_diff_train_T.shape[1], n_features))\n",
    "\n",
    "X_diff_test_T, y_diff_test_T = split_sequence(diff_test_T.values, n_steps)\n",
    "X_diff_test_T = X_diff_test_T.reshape((X_diff_test_T.shape[0],\n",
    "                                       X_diff_test_T.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_part():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128,\n",
    "              input_shape=(n_steps, n_features),\n",
    "              return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam' , loss='mean_squared_error', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 190ms/step - loss: 0.3855 - mse: 0.3855 - val_loss: 0.1255 - val_mse: 0.1255\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3285 - mse: 0.3285 - val_loss: 0.1120 - val_mse: 0.1120\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2916 - mse: 0.2916 - val_loss: 0.0881 - val_mse: 0.0881\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2681 - mse: 0.2681 - val_loss: 0.0775 - val_mse: 0.0775\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.0681 - val_mse: 0.0681\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1992 - mse: 0.1992 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1927 - mse: 0.1927 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1721 - mse: 0.1721 - val_loss: 0.0494 - val_mse: 0.0494\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1617 - mse: 0.1617 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1356 - mse: 0.1356 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1220 - mse: 0.1220 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1030 - mse: 0.1030 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0839 - mse: 0.0839 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0640 - mse: 0.0640 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0622 - mse: 0.0622 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0558 - mse: 0.0558 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0488 - mse: 0.0488 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 9.1138e-04 - val_mse: 9.1138e-04\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 5.8663e-04 - val_mse: 5.8663e-04\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 4.2996e-04 - val_mse: 4.2996e-04\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 7.1542e-04 - val_mse: 7.1542e-04\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 6.7731e-04 - val_mse: 6.7731e-04\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 7.9920e-04 - val_mse: 7.9920e-04\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.6659e-04 - val_mse: 2.6659e-04\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 2.5692e-04 - val_mse: 2.5692e-04\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 3.0098e-04 - val_mse: 3.0098e-04\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 3.2050e-04 - val_mse: 3.2050e-04\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 2.4524e-04 - val_mse: 2.4524e-04\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 6.9967e-04 - val_mse: 6.9967e-04\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 6.7762e-04 - val_mse: 6.7762e-04\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 5.5689e-04 - val_mse: 5.5689e-04\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 4.2694e-04 - val_mse: 4.2694e-04\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 1.0655e-04 - val_mse: 1.0655e-04\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 2.9545e-04 - val_mse: 2.9545e-04\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 2.5527e-04 - val_mse: 2.5527e-04\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 7.8315e-05 - val_mse: 7.8315e-05\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.7123e-04 - val_mse: 2.7123e-04\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 1.9699e-04 - val_mse: 1.9699e-04\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 1.0820e-04 - val_mse: 1.0820e-04\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 1.6969e-04 - val_mse: 1.6969e-04\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 1.4229e-04 - val_mse: 1.4229e-04\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 2.1384e-04 - val_mse: 2.1384e-04\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 3.3910e-04 - val_mse: 3.3910e-04\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 2.9134e-04 - val_mse: 2.9134e-04\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.0787e-04 - val_mse: 2.0787e-04\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.3086e-04 - val_mse: 1.3086e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 8.9387e-05 - val_mse: 8.9387e-05\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 1.1515e-04 - val_mse: 1.1515e-04\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.3150e-04 - val_mse: 1.3150e-04\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.5746e-04 - val_mse: 1.5746e-04\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.0433e-04 - val_mse: 1.0433e-04\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.1021e-04 - val_mse: 1.1021e-04\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.7036e-04 - val_mse: 1.7036e-04\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.5331e-04 - val_mse: 2.5331e-04\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.4578e-04 - val_mse: 2.4578e-04\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.8825e-04 - val_mse: 1.8825e-04\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.6533e-04 - val_mse: 1.6533e-04\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 1.0595e-04 - val_mse: 1.0595e-04\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.5783e-04 - val_mse: 1.5783e-04\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.8073e-04 - val_mse: 1.8073e-04\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 1.4214e-04 - val_mse: 1.4214e-04\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.7086e-04 - val_mse: 2.7086e-04\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 2.3353e-04 - val_mse: 2.3353e-04\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.5704e-04 - val_mse: 1.5704e-04\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 9.6327e-05 - val_mse: 9.6327e-05\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.0516e-04 - val_mse: 1.0516e-04\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 2.0887e-04 - val_mse: 2.0887e-04\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 3.2080e-04 - val_mse: 3.2080e-04\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.3686e-04 - val_mse: 1.3686e-04\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.2916e-04 - val_mse: 1.2916e-04\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.4194e-04 - val_mse: 2.4194e-04\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.7473e-04 - val_mse: 1.7473e-04\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.6960e-04 - val_mse: 1.6960e-04\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.4323e-04 - val_mse: 2.4323e-04\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.2580e-04 - val_mse: 1.2580e-04\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.2104e-04 - val_mse: 1.2104e-04\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.1911e-04 - val_mse: 1.1911e-04\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 2.3151e-04 - val_mse: 2.3151e-04\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 1.8218e-04 - val_mse: 1.8218e-04\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 9.9708e-05 - val_mse: 9.9708e-05\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.3153e-04 - val_mse: 1.3153e-04\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 2.0089e-04 - val_mse: 2.0089e-04\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 2.0919e-04 - val_mse: 2.0919e-04\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.8971e-04 - val_mse: 2.8971e-04\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 1.5943e-04 - val_mse: 1.5943e-04\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 8.0871e-05 - val_mse: 8.0871e-05\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.4489e-04 - val_mse: 1.4489e-04\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.0788e-04 - val_mse: 1.0788e-04\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.6769e-04 - val_mse: 1.6769e-04\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 2.7848e-04 - val_mse: 2.7848e-04\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.8893e-04 - val_mse: 2.8893e-04\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 3.2416e-04 - val_mse: 3.2416e-04\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 2.7618e-04 - val_mse: 2.7618e-04\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 5.2733e-05 - val_mse: 5.2733e-05\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.6812e-04 - val_mse: 1.6812e-04\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.6215e-04 - val_mse: 2.6215e-04\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.5065e-04 - val_mse: 1.5065e-04\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.4319e-04 - val_mse: 1.4319e-04\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.1582e-04 - val_mse: 1.1582e-04\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.3214e-04 - val_mse: 1.3214e-04\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.5668e-04 - val_mse: 1.5668e-04\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 2.1794e-04 - val_mse: 2.1794e-04\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.6310e-04 - val_mse: 2.6310e-04\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 1.7105e-04 - val_mse: 1.7105e-04\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.8909e-04 - val_mse: 1.8909e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.9760e-04 - val_mse: 1.9760e-04\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 1.2257e-04 - val_mse: 1.2257e-04\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 2.1576e-04 - val_mse: 2.1576e-04\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.5020e-04 - val_mse: 1.5020e-04\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 9.9542e-05 - val_mse: 9.9542e-05\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.7498e-04 - val_mse: 1.7498e-04\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.2225e-04 - val_mse: 2.2225e-04\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.4505e-04 - val_mse: 1.4505e-04\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.4606e-04 - val_mse: 1.4606e-04\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.9154e-04 - val_mse: 1.9154e-04\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.8673e-04 - val_mse: 1.8673e-04\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 1.5727e-04 - val_mse: 1.5727e-04\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.2894e-04 - val_mse: 1.2894e-04\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.7701e-04 - val_mse: 1.7701e-04\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 1.7831e-04 - val_mse: 1.7831e-04\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.5163e-04 - val_mse: 1.5163e-04\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.7160e-04 - val_mse: 1.7160e-04\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.8890e-04 - val_mse: 1.8890e-04\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.5116e-04 - val_mse: 1.5116e-04\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.2222e-04 - val_mse: 1.2222e-04\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.3829e-04 - val_mse: 2.3829e-04\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 3.0656e-04 - val_mse: 3.0656e-04\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 9.9972e-05 - val_mse: 9.9972e-05\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.4400e-04 - val_mse: 1.4400e-04\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 3.3632e-04 - val_mse: 3.3632e-04\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 3.3027e-04 - val_mse: 3.3027e-04\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.6350e-04 - val_mse: 2.6350e-04\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.5929e-04 - val_mse: 1.5929e-04\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 1.1847e-04 - val_mse: 1.1847e-04\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.6392e-04 - val_mse: 1.6392e-04\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4166e-04 - val_mse: 1.4166e-04\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 9.7255e-05 - val_mse: 9.7255e-05\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4408e-04 - val_mse: 1.4408e-04\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 2.3640e-04 - val_mse: 2.3640e-04\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.6986e-04 - val_mse: 1.6986e-04\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 1.1616e-04 - val_mse: 1.1616e-04\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 6.7395e-05 - val_mse: 6.7395e-05\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.7891e-04 - val_mse: 1.7891e-04\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.6022e-04 - val_mse: 1.6022e-04\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 9.7759e-05 - val_mse: 9.7759e-05\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 1.8157e-04 - val_mse: 1.8157e-04\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 2.1911e-04 - val_mse: 2.1911e-04\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 2.0025e-04 - val_mse: 2.0025e-04\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.6584e-04 - val_mse: 1.6584e-04\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.2479e-04 - val_mse: 1.2479e-04\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 9.2535e-05 - val_mse: 9.2535e-05\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 2.6952e-04 - val_mse: 2.6952e-04\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 2.4499e-04 - val_mse: 2.4499e-04\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.3014e-04 - val_mse: 1.3014e-04\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 1.9827e-04 - val_mse: 1.9827e-04\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.9863e-04 - val_mse: 1.9863e-04\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 9.6348e-05 - val_mse: 9.6348e-05\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.7278e-04 - val_mse: 1.7278e-04\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 2.1998e-04 - val_mse: 2.1998e-04\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 1.1024e-04 - val_mse: 1.1024e-04\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 1.3215e-04 - val_mse: 1.3215e-04\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 2.3715e-04 - val_mse: 2.3715e-04\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.1390e-04 - val_mse: 2.1390e-04\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.6982e-04 - val_mse: 1.6982e-04\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 2.0111e-04 - val_mse: 2.0111e-04\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.1880e-04 - val_mse: 1.1880e-04\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.0344e-04 - val_mse: 1.0344e-04\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.8806e-04 - val_mse: 1.8806e-04\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.4149e-04 - val_mse: 1.4149e-04\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 1.2177e-04 - val_mse: 1.2177e-04\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.4949e-04 - val_mse: 1.4949e-04\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.2259e-04 - val_mse: 1.2259e-04\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 1.0250e-04 - val_mse: 1.0250e-04\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 1.0330e-04 - val_mse: 1.0330e-04\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 9.2275e-05 - val_mse: 9.2275e-05\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 1.2230e-04 - val_mse: 1.2230e-04\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 1.3317e-04 - val_mse: 1.3317e-04\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 6.2495e-05 - val_mse: 6.2495e-05\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 7.3722e-05 - val_mse: 7.3722e-05\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 2.1076e-04 - val_mse: 2.1076e-04\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 1.8066e-04 - val_mse: 1.8066e-04\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 9.9351e-05 - val_mse: 9.9351e-05\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 1.0259e-04 - val_mse: 1.0259e-04\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 9.5536e-05 - val_mse: 9.5536e-05\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 8.5732e-05 - val_mse: 8.5732e-05\n"
     ]
    }
   ],
   "source": [
    "RNN_model = RNN_part()\n",
    "history_RNN = RNN_model.fit(X_diff_train_T, y_diff_train_T,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_RNN.history['loss'])\n",
    "plt.plot(history_RNN.history['val_loss'])\n",
    "plt.title('RNN model Loss')\n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me run `callback` function to see the effect of early stopping in deep learning. \n",
    "Early stopping is a tool to employ against overfitting in the sense that it helps us to regularize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other pros of early stopping is to save time, because training a deep learning model takes time. In early stopping, once the model reaches the target performance, the algorithm automatically stops. In other word, thanks to `patience` paramater below, training stops after the number of epochs without improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.3724 - mse: 0.3724 - val_loss: 0.1289 - val_mse: 0.1289\n"
     ]
    }
   ],
   "source": [
    "RNN_model = RNN_part()\n",
    "history_RNN = RNN_model.fit(X_diff_train_T, y_diff_train_T,\n",
    "                            batch_size=200,\n",
    "                            epochs=200,\n",
    "                            validation_split=0.2, \n",
    "                            callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = X_diff_test_T[X_diff_test_T.shape[0]-1]\n",
    "T_input = start\n",
    "T_input = T_input.reshape((1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_T = []\n",
    "\n",
    "for i in range(len(arima_predictions_T)):\n",
    "    T_input = T_input.reshape((1, n_steps, n_features))\n",
    "    yhat = RNN_model.predict(T_input, verbose=0)\n",
    "    T_input = np.append(T_input, yhat)\n",
    "    T_input = T_input[1:]\n",
    "    predictions_T.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,yhat):\n",
    "    return np.sqrt(mean_squared_error(y,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of AT&T for RNN model 0.4540\n"
     ]
    }
   ],
   "source": [
    "print('RMSE of AT&T for RNN model {:.4f}'\\\n",
    "      .format(rmse(diff_test_T, np.array(predictions_T).flatten())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
